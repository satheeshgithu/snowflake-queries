import streamlit as st
from snowflake.snowpark.context import get_active_session
import json
from datetime import datetime
import pandas as pd
import io
import streamlit as st
import pandas as pd
import json
import re




# ‚úÖ MUST be first Streamlit command
st.set_page_config(
    page_title="Snowflake Storage Integration Manager",
    layout="wide"
)

# -------------------------------
# Session State Init
# -------------------------------

if "setup_complete" not in st.session_state:
    st.session_state.setup_complete = False

if "config_db" not in st.session_state:
    st.session_state.config_db = None

if "config_schema" not in st.session_state:
    st.session_state.config_schema = None

if "storage_integration" not in st.session_state:
    st.session_state.storage_integration = None

# if st.session_state.setup_complete:
#     with st.sidebar:
#         st.markdown("### ‚öôÔ∏è Environment Settings")

#         if st.button("üîß Modify Setup Configuration", use_container_width=True):
#             st.session_state.setup_complete = False
#             st.rerun()

#         st.markdown("---")
#         st.markdown("**Current Configuration:**")
#         st.markdown(f"üíæ Database: `{st.session_state.config_db}`")
#         st.markdown(f"üìÅ Schema: `{st.session_state.config_schema}`")
#         st.markdown(f"üì¶ Integration: `{st.session_state.storage_integration}`")


# -------------------------------
# Setup Page Toggle
# -------------------------------

if not st.session_state.setup_complete:

    # st.title("üîß Storage Integration Setup")

    st.title("‚ùÑÔ∏è Snowflake Storage Integration Manager")
    
    session = st.connection("snowflake").session()
    
    # ============================================================
    # SESSION STATE
    # ============================================================
    for key in ["details", "creation_success"]:
        if key not in st.session_state:
            st.session_state[key] = None
    
    # ============================================================
    # DATABASE & SCHEMA SETUP
    # ============================================================
    # st.sidebar.header("üóÑÔ∏è Database & Schema Setup")
    
    # mode = st.sidebar.radio(
    #     "Choose Mode",
    #     ["üîπ Use Existing", "‚ûï Create New"],
    #     horizontal=True
    # )
    
    # def get_current_db_schema():
    #     row = session.sql(
    #         "SELECT CURRENT_DATABASE() AS DB, CURRENT_SCHEMA() AS SCHEMA"
    #     ).collect()[0]
    #     return row["DB"], row["SCHEMA"]
    
    # if mode == "üîπ Use Existing":
    #     CONFIG_DB, CONFIG_SCHEMA = get_current_db_schema()
    #     st.sidebar.success(f"Database: {CONFIG_DB}")
    #     st.sidebar.success(f"Schema: {CONFIG_SCHEMA}")
    # else:
    #     CONFIG_DB = st.sidebar.text_input("New Database Name")
    #     CONFIG_SCHEMA = st.sidebar.text_input("New Schema Name")
    


    # def get_all_databases_schemas(session):
    #     """
    #     Fetch all existing DBs & Schemas from ACCOUNT_USAGE.SCHEMATA
    #     """
    #     query = """
    #     SELECT DISTINCT
    #         catalog_name AS CATALOG_NAME,
    #         schema_name AS SCHEMA_NAME
    #     FROM SNOWFLAKE.ACCOUNT_USAGE.SCHEMATA
    #     WHERE deleted IS NULL
    #     ORDER BY catalog_name, schema_name
    #     """
    #     try:
    #         df = session.sql(query).to_pandas()
    #         return df
    #     except Exception as e:
    #         st.error(f"Query failed: {e}")
    #         return pd.DataFrame()
    
    # def valid_name(name):
    #     import re
    #     return bool(re.match(r"^[a-zA-Z0-9_]+$", name))
    
    # # ========================================
    # # Sidebar: Database & Schema Selection
    # # ========================================
    # st.sidebar.header("üóÑÔ∏è Database & Schema Setup")
    
    # mode = st.sidebar.radio("Choose Mode", ["üîπ Select Existing", "‚ûï Create New"], horizontal=True)
    
    # if mode == "üîπ Select Existing":
    #     # Load all DBs/Schemas
    #     schemas_df = get_all_databases_schemas(session)
        
    #     if not schemas_df.empty:
    #         # Multi-select dropdown
    #         selected = st.sidebar.multiselect(
    #             "Select DB.Schema:",
    #             options=schemas_df['CATALOG_NAME'] + "." + schemas_df['SCHEMA_NAME'].astype(str),
    #             format_func=lambda x: x,
    #             max_selections=1,
    #             default=None
    #         )
            
    #         if selected:
    #             CONFIG_DB, CONFIG_SCHEMA = selected[0].split(".", 1)
    #             st.sidebar.success(f"‚úÖ **Database**: `{CONFIG_DB}`")
    #             st.sidebar.success(f"‚úÖ **Schema**: `{CONFIG_SCHEMA}`")
                
    #             # Show table preview
    #             tables_query = f"""
    #             SELECT table_name 
    #             FROM "{CONFIG_DB}"."{CONFIG_SCHEMA}".information_schema.tables 
    #             WHERE table_type = 'BASE TABLE'
    #             ORDER BY table_name
    #             """
    #             try:
    #                 tables_df = session.sql(tables_query).to_pandas()
    #                 if not tables_df.empty:
    #                     st.sidebar.markdown("**üìã Tables:**")
    #                     st.sidebar.dataframe(tables_df, use_container_width=True)
    #             except:
    #                 pass
                    
    #         else:
    #             st.sidebar.info("üëÜ Select a database/schema")
    #     else:
    #         st.sidebar.warning("‚ö†Ô∏è No schemas found - ACCOUNT_USAGE latency ~2hrs")
    
    # else:  # Create New
    #     col1, col2 = st.sidebar.columns(2)
    #     with col1:
    #         CONFIG_DB = st.text_input("Database", placeholder="CONFIG_DB")
    #     with col2:
    #         CONFIG_SCHEMA = st.text_input("Schema", placeholder="PUBLIC")
        
    #     if st.sidebar.button("üöÄ Create", type="primary"):
    #         if CONFIG_DB and CONFIG_SCHEMA:
    #             if valid_name(CONFIG_DB) and valid_name(CONFIG_SCHEMA):
    #                 session.sql(f'CREATE DATABASE IF NOT EXISTS "{CONFIG_DB}"').collect()
    #                 session.sql(f'CREATE SCHEMA IF NOT EXISTS "{CONFIG_DB}"."{CONFIG_SCHEMA}"').collect()
    #                 st.sidebar.success("‚úÖ Created!")
    #                 st.rerun()
    #             else:
    #                 st.sidebar.error("‚ùå Letters/numbers/_ only")
    #         else:
    #             st.sidebar.warning("‚ö†Ô∏è Fill both fields")
    
    # # Use globally
    # if 'CONFIG_DB' in locals() and 'CONFIG_SCHEMA' in locals():
    #     FULL_CONFIG_TABLE = f'"{CONFIG_DB}"."{CONFIG_SCHEMA}".INTERATION_INFO'
    #     st.info(f"Using: `{FULL_CONFIG_TABLE}`")



    def get_all_databases_schemas(session):
        """Fetch all existing DBs & Schemas from ACCOUNT_USAGE.SCHEMATA"""
        query = """
        SELECT DISTINCT
            catalog_name AS CATALOG_NAME,
            schema_name AS SCHEMA_NAME
        FROM SNOWFLAKE.ACCOUNT_USAGE.SCHEMATA
        WHERE deleted IS NULL
        ORDER BY catalog_name, schema_name
        """
        try:
            df = session.sql(query).to_pandas()
            return df
        except Exception as e:
            st.error(f"Query failed: {e}")
            return pd.DataFrame()
    
    def ensure_database(session, db_name):
        """Ensure database exists"""
        session.sql(f'CREATE DATABASE IF NOT EXISTS "{db_name}"').collect()
        st.sidebar.success(f"‚úÖ Database `{db_name}` ready")
    
    def ensure_schema(session, db_name, schema_name):
        """Ensure schema exists"""
        session.sql(f'CREATE SCHEMA IF NOT EXISTS "{db_name}"."{schema_name}"').collect()
        st.sidebar.success(f"‚úÖ Schema `{schema_name}` ready")


    
    def ensure_config_table(session, db_name, schema_name):
        """Ensure INTERATION_INFO config table exists with correct schema"""
        full_table = f'"{db_name}"."{schema_name}".INTERATION_INFO'
        
        # Create table with all required columns

        session.sql(f"""
            CREATE TABLE IF NOT EXISTS  {full_table} (
                NAME STRING,
                TYPE STRING,
                CATEGORY STRING,
                ENABLED STRING,
                COMMENT STRING,
                CREATED_ON  NUMBER(38,0)
            )
        """).collect()
        
        
        # Bootstrap with existing integrations if empty
        count = session.sql(f'SELECT COUNT(*) as cnt FROM {full_table}').collect()[0]['CNT']
        if count == 0:
            st.sidebar.info("üì• Bootstrapping config table...")
            # Add your bootstrap logic here
            st.sidebar.success("‚úÖ Config table ready!")
        
        return full_table
    
    def valid_name(name):
        import re
        return bool(re.match(r"^[a-zA-Z0-9_]+$", name))
    
    # ========================================
    # Sidebar: Database & Schema Selection
    # ========================================
    st.sidebar.header("üóÑÔ∏è Database & Schema Setup")
    
    mode = st.sidebar.radio("Choose Mode", ["üîπ Select Existing", "‚ûï Create New"], horizontal=True)
    
    CONFIG_DB = None
    CONFIG_SCHEMA = None
    FULL_CONFIG_TABLE = None
    
    
    if mode == "üîπ Select Existing":
        schemas_df = get_all_databases_schemas(session)
        
        if not schemas_df.empty:
            options = schemas_df['CATALOG_NAME'] + "." + schemas_df['SCHEMA_NAME'].astype(str)
            selected = st.sidebar.selectbox(
                "Select DB.Schema:",
                options=options,
                index=None,
                placeholder="Choose existing DB.Schema..."
            )
            
            if selected:
                CONFIG_DB, CONFIG_SCHEMA = selected.split(".", 1)
                st.sidebar.success(f"‚úÖ **Database**: `{CONFIG_DB}`")
                st.sidebar.success(f"‚úÖ **Schema**: `{CONFIG_SCHEMA}`")
                
                # üî• ADD ENSURE FUNCTIONS HERE
                if CONFIG_DB and CONFIG_SCHEMA:
                    ensure_database(session, CONFIG_DB)
                    ensure_schema(session, CONFIG_DB, CONFIG_SCHEMA)
                    FULL_CONFIG_TABLE = ensure_config_table(session, CONFIG_DB, CONFIG_SCHEMA)
                    
                    # Show table status
                    st.sidebar.markdown("**üìä Config Table Status:**")
                    count = session.sql(f'SELECT COUNT(*) FROM {FULL_CONFIG_TABLE}').collect()[0][0]
                    st.sidebar.metric("Integrations", count)
    
        else:
            st.sidebar.warning("‚ö†Ô∏è No schemas found")
    
    else:  # Create New
        col1, col2 = st.sidebar.columns(2)
        with col1:
            CONFIG_DB = st.text_input("Database", placeholder="CONFIG_DB")
        with col2:
            CONFIG_SCHEMA = st.text_input("Schema", placeholder="PUBLIC")
        
        if st.sidebar.button("üöÄ Create", type="primary"):
            if CONFIG_DB and CONFIG_SCHEMA:
                if valid_name(CONFIG_DB) and valid_name(CONFIG_SCHEMA):
                    ensure_database(session, CONFIG_DB)
                    ensure_schema(session, CONFIG_DB, CONFIG_SCHEMA)
                    FULL_CONFIG_TABLE = ensure_config_table(session, CONFIG_DB, CONFIG_SCHEMA)
                    st.sidebar.success("‚úÖ All created!")
                    st.rerun()
                else:
                    st.sidebar.error("‚ùå Letters/numbers/_ only")
            else:
                st.sidebar.warning("‚ö†Ô∏è Fill both fields")
    
    # ========================================
    # Use in Main App
    # ========================================
    if FULL_CONFIG_TABLE:
        st.info(f"üéØ Using config table: `{FULL_CONFIG_TABLE}`")
        
        # Your existing app logic here
        # df = session.sql(f'SELECT * FROM {FULL_CONFIG_TABLE}').to_pandas()
        # st.dataframe(df)


    
    
    # # ============================================================
    # # ENSURE DB / SCHEMA / TABLE
    # # ============================================================
    # def ensure_database(db):
    #     session.sql(f"CREATE DATABASE IF NOT EXISTS {db}").collect()
    
    # def ensure_schema(db, schema):
    #     session.sql(f"CREATE SCHEMA IF NOT EXISTS {db}.{schema}").collect()
    
    # def ensure_config_table(db, schema):
    #     session.sql(f"""
    #         CREATE TABLE IF NOT EXISTS {db}.{schema}.INTERATION_INFO (
    #             NAME STRING,
    #             TYPE STRING,
    #             CATEGORY STRING,
    #             ENABLED STRING,
    #             COMMENT STRING,
    #             CREATED_ON  NUMBER(38,0)
    #         )
    #     """).collect()
    
    # if CONFIG_DB and CONFIG_SCHEMA:
    #     ensure_database(CONFIG_DB)
    #     ensure_schema(CONFIG_DB, CONFIG_SCHEMA)
    #     ensure_config_table(CONFIG_DB, CONFIG_SCHEMA)
    
    # FULL_CONFIG_TABLE = f"{CONFIG_DB}.{CONFIG_SCHEMA}.INTERATION_INFO"
    
    # ============================================================
    # FIXED BOOTSTRAP CONFIG TABLE
    # ============================================================
    def bootstrap_config_table(session, database, schema):
        df = session.sql("SHOW STORAGE INTEGRATIONS").to_pandas()
        
        if df.empty:
            return
        
        df.columns = df.columns.str.replace('"','').str.upper()
        
        required = ["NAME", "TYPE", "CATEGORY", "ENABLED", "COMMENT", "CREATED_ON"]
        
        for c in required:
            if c not in df.columns:
                df[c] = None
        
        df_final = df[required].copy()
        
        # Convert to lowercase to match table schema
        df_final.columns = df_final.columns.str.lower()
        
        df_final["created_on"] = pd.to_datetime(
            df_final["created_on"],
            errors="coerce"
        )
        
        session.write_pandas(
            df_final,
            table_name="INTERATION_INFO",
            database=database,
            schema=schema,
            auto_create_table=False,
            overwrite=True,
            quote_identifiers=False  # Add this
        )
    

    
    def insert_integration_to_config(database, schema, integration_name):
    
        df = session.sql(
            f"SHOW STORAGE INTEGRATIONS LIKE '{integration_name}'"
        ).to_pandas()
    
        if df.empty:
            st.warning("SHOW returned no rows")
            return
    
        # normalize case
        df.columns = df.columns.str.replace('"','').str.upper()
    
        required = ["NAME","TYPE","CATEGORY","ENABLED","COMMENT","CREATED_ON"]
    
        # keep only columns that actually exist
        available = [c for c in required if c in df.columns]
    
        if not available:
            st.error(f"Unexpected SHOW format ‚Üí columns = {df.columns.tolist()}")
            return
    
        df = df[available]
    
        # add missing columns if needed
        for c in required:
            if c not in df.columns:
                df[c] = None
    
        df = df[required]
    
        session.write_pandas(
            df,
            table_name="INTERATION_INFO",
            database=database,
            schema=schema,
            auto_create_table=False
        )
    
        st.success("Config table updated")
    
    
    
    bootstrap_config_table(session, CONFIG_DB, CONFIG_SCHEMA)
    
    # ============================================================
    # HELPERS
    # ============================================================
    # def get_integrations():
    #     df = session.sql(
    #         f'SELECT NAME FROM {FULL_CONFIG_TABLE} ORDER BY CREATED_ON DESC'
    #     ).to_pandas()
    
    #     return df["NAME"].tolist() if not df.empty else []

    def get_integrations():
    
        # full_table = st.session_state.get("full_config_table")
    
        # if not full_table:   
        #     st.warning("Config table not initialized yet")
        #     return []
    
        try:
            df = session.sql(
                f'SELECT NAME FROM {FULL_CONFIG_TABLE} ORDER BY CREATED_ON DESC'
            ).to_pandas()
    
            # if df.empty:
            #     return []
    
            # # normalize just in case
            # df.columns = df.columns.str.lower()
    
            return df["NAME"].tolist() if not df.empty else []
    
        except Exception as e:
            st.warning(f"Select Database & Schema")
            return []
            
    def get_unique_name(session, base_name, FULL_CONFIG_TABLE):
    
        try:
            df = session.sql(
                f"SELECT NAME FROM {FULL_CONFIG_TABLE}"
            ).to_pandas()
    
            existing = set(df["NAME"].tolist())
    
        except:
            existing = set()
    
        if base_name not in existing:
            return base_name
    
        i = 1
        while True:
            new_name = f"{base_name}_{i}"
            if new_name not in existing:
                return new_name
            i += 1


    
    
    def create_storage_integration(session,name,provider,credential,locations,FULL_CONFIG_TABLE):
    
        final_name = get_unique_name(
            session,
            name,
            FULL_CONFIG_TABLE
        )

        if final_name != name:
            st.warning(f"Name already exists ‚Äî created {final_name} create with another name")

    
        if provider == "S3":
            sql = f"""
            CREATE  STORAGE INTEGRATION {final_name}
            TYPE = EXTERNAL_STAGE
            STORAGE_PROVIDER = 'S3'
            ENABLED = TRUE
            STORAGE_AWS_ROLE_ARN = '{credential}'
            STORAGE_ALLOWED_LOCATIONS = ({','.join(f"'{l}'" for l in locations)})
            """
        elif provider == "GCS":
            sql = f"""
            CREATE  STORAGE INTEGRATION {final_name}
            TYPE = EXTERNAL_STAGE
            STORAGE_PROVIDER = 'GCS'
            ENABLED = TRUE
            STORAGE_GOOGLE_SERVICE_ACCOUNT = '{credential}'
            STORAGE_ALLOWED_LOCATIONS = ({','.join(f"'{l}'" for l in locations)})
            """
        else:
            sql = f"""
            CREATE STORAGE INTEGRATION {final_name}
            TYPE = EXTERNAL_STAGE
            STORAGE_PROVIDER = 'AZURE'
            ENABLED = TRUE
            STORAGE_ALLOWED_LOCATIONS = ({','.join(f"'{l}'" for l in locations)})
            """
        
        session.sql(sql).collect()
        st.success(f"‚úÖ Integration created: {final_name}")
    
    def describe_integration(name):
    
        try:
            if not name:
                return None
    
            df = session.sql(
                f'DESC STORAGE INTEGRATION "{name}"'
            ).to_pandas()
    
            if df.empty:
                st.warning("DESC returned no rows")
                return None
    
            # normalize column names
            df.columns = [c.strip().lower() for c in df.columns]
    
            # auto detect columns
            prop_col = next(
                (c for c in df.columns if "property" in c or c == "name"),
                None
            )
            val_col = next(
                (c for c in df.columns if "property_value" in c),
                None
            )
    
            if not prop_col or not val_col:
                st.error(f"Unexpected DESC format ‚Üí {df.columns.tolist()}")
                st.dataframe(df)
                return None
    
            props = dict(zip(df[prop_col], df[val_col]))
    
            return {
                "PROVIDER": props.get("STORAGE_PROVIDER", "N/A"),
                # "STORAGE_AWS_ROLE_ARN": props.get("STORAGE_AWS_ROLE_ARN", "N/A"),
                "LOCATIONS": props.get("STORAGE_ALLOWED_LOCATIONS", "N/A"),
                "IAM_ARN": props.get("STORAGE_AWS_IAM_USER_ARN", "N/A"),
                "EXTERNAL_ID": props.get("STORAGE_AWS_EXTERNAL_ID", "N/A")
            }
    
        except Exception as e:
            st.error(f"DESC failed: {e}")
            return None
    
    
    def build_trust_policy(iam_arn, external_id):
        return {
            "Version": "2012-10-17",
            "Statement": [{
                "Effect": "Allow",
                "Principal": {"AWS": iam_arn},
                "Action": "sts:AssumeRole",
                "Condition": {
                    "StringEquals": {
                        "sts:ExternalId": external_id
                    }
                }
            }]
        }
    
    # ============================================================
    # UI
    # ============================================================
    # st.subheader("üîß Storage Integration Manager")
    col_title, col_doc = st.columns([6,1])
    
    with col_title:  
        st.title("üîß Storage Integration")
    
    with col_doc:
        st.link_button(
            "üìò",
            "https://docs.snowflake.com/en/user-guide/data-load-s3-config-storage-integration"
        )
    
    
    options = ["‚ûï Create New"] + get_integrations()
    choice = st.selectbox("Select Integration", options)
    
    # ============================================================
    # CREATE NEW - FIXED INDENTATION
    # ============================================================
    if choice == "‚ûï Create New":
        col1, col2 = st.columns(2)
    
        with col1:
            name = st.text_input("Integration Name")
            provider = st.selectbox("Provider", ["S3", "GCS", "AZURE"])
    
        with col2:
            credential = st.text_input(
                "Credential",
                placeholder="arn:aws:iam::123456789012:role/my-role"
            )
    
        locations_input = st.text_area(
            "Allowed Locations (comma separated)",
            placeholder="s3://my-bucket/path/, s3://other-bucket/data/"
        )
    
        location_list = [l.strip() for l in locations_input.split(",") if l.strip()]

    
        # Validation with visual feedback
        name_ok = bool(name.strip())
        credential_ok = bool(credential.strip())
        locations_ok = len(location_list) > 0
        
        col1, col2, col3 = st.columns(3)
        col1.metric("Name", "*" if name_ok else "x")
        col2.metric("Credential", "*" if credential_ok else "x")
        col3.metric("Locations", f"{len(location_list)} *" if locations_ok else "x")
    
        if st.button("üöÄ Create Integration", type="primary"):
        
            name_clean = name.strip()
            credential_clean = credential.strip()
        
            with st.spinner("Creating integration..."):
        
                # STEP 1 ‚Äî create integration
                create_storage_integration(session,name,provider,credential,location_list,FULL_CONFIG_TABLE)
        
                # STEP 2 ‚Äî insert into config table
                insert_integration_to_config(
                    CONFIG_DB,
                    CONFIG_SCHEMA,
                    name
                )
        
                # STEP 3 ‚Äî describe integration
                st.session_state.details = describe_integration(name)
        
            st.success("‚úÖ Integration created and saved to config table")
            st.rerun()

     
    
    # ============================================================
    # EXISTING INTEGRATION
    # ============================================================
    else:
        col1, col2 = st.columns(2)
    
        with col1:
            # if st.button("üîç DESC Integration"):
            #     st.session_state.details = describe_integration(choice)
                
    
            if st.button("üîç DESC Integration") and choice != "‚ûï Create New":
                st.session_state.details = describe_integration(choice)
                st.rerun()
    
        with col2:
            if st.button("üìú Generate Policy"):
                st.session_state.details = describe_integration(choice)
                st.rerun()
    
    # ============================================================
    # SUCCESS MESSAGE
    # ============================================================
    if st.session_state.creation_success:
        st.success("üéä **Integration created and ready for use!** üéä")
        if st.button("‚úÖ Continue"):
            st.session_state.creation_success = False
            st.rerun()
    
    # ============================================================
    # DETAILS + POLICY
    # ============================================================
    if st.session_state.details:
        st.markdown("---")
        tab1, tab2 = st.tabs(["üîê Details", "üìú Policy JSON"])
    
        with tab1:
            d = st.session_state.details
            col1, col2 = st.columns(2)
            with col1:
                st.metric("Provider", d["PROVIDER"] or "N/A")
                st.text_area("Allowed Locations", d["LOCATIONS"] or "N/A", height=100)
            with col2:
                st.text_input("IAM User ARN", d["IAM_ARN"] or "N/A")
                st.text_input("External ID", d["EXTERNAL_ID"] or "N/A")
    
        with tab2:
            d = st.session_state.details
            if d["IAM_ARN"] and d["EXTERNAL_ID"]:
                policy = build_trust_policy(d["IAM_ARN"], d["EXTERNAL_ID"])
                st.code(json.dumps(policy, indent=4), language="json")
                st.download_button(
                    "‚¨áÔ∏è Download Policy",
                    json.dumps(policy, indent=4),
                    file_name=f"{choice}_trust_policy.json"
                )
            else:
                st.warning("‚ùå IAM details not available - only S3 integrations have policy")
    
    # # ============================================================
    # # CONFIG TABLE VIEW
    # # ============================================================
    # st.markdown("---")
    # st.subheader("üìã Config Table")
    
    # try:
    #     df = session.sql(
    #         f'SELECT * FROM {FULL_CONFIG_TABLE} ORDER BY CREATED_ON DESC'
    #     ).to_pandas()
    #     if not df.empty:
    #         st.dataframe(df, use_container_width=True)
    #     else:
    #         st.info("üìù No integrations found. Create your first one above!")
    # except Exception as e:
    #     st.error(f"Table error: {e}")
    #     st.info("Table may not exist yet - create an integration first")

    # ============================================================
    # FILE FORMAT BUILDER (CSV / JSON / PARQUET)
    # ============================================================
    
    # st.markdown("---")
    # st.subheader("üìÇ File Format Builder")
    
    # colf1, colf2 = st.columns(2)
    
    # with colf1:
    #     ff_name = st.text_input(
    #         "File Format Name",
    #         value="CDC_FORMAT",
    #         key="ff_name_input"
    #     )
    
    # with colf2:
    #     ff_type = st.selectbox(
    #         "üìÑ File Type",
    #         ["CSV", "JSON", "PARQUET"],
    #         key="ff_type_select"
    #     )
    
    # # ------------------------------------------------
    # # CSV OPTIONS (Your Required Defaults)
    # # ------------------------------------------------
    
    # if ff_type == "CSV":
    
    #     st.markdown("### üìÑ CSV Format Settings")
    
    #     delimiter = st.text_input("Delimiter", ",", key="csv_delim")
    #     parse_header = st.checkbox("PARSE_HEADER", True, key="csv_parse_header")
    #     trim_space = st.checkbox("TRIM_SPACE", True, key="csv_trim")
    #     replace_invalid = st.checkbox("REPLACE_INVALID_CHARACTERS", True, key="csv_replace")
    #     escape_unenclosed_field = st.checkbox("ESCAPE_UNENCLOSED_FIELD", True, key="csv_escape_unenclosed_field")
    #     field_optionally_enclosed_by = st.checkbox("FIELD_OPTIONALLY_ENCLOSED_BY", True, key="csv_field_optionally_enclosed_by")
    #     error_on_column_count_mismatch = st.checkbox("ERROR_ON_COLUMN_COUNT_MISMATCH", True, key="csv_error_on_column_count_mismatch")
    #     null_if = st.checkbox("NULL_IF", True, key="csv_null_if")
    #     replace_invalid_characters = st.checkbox("REPLACE_INVALID_CHARACTERS", True, key="csv_replace_invalid_characters")



    
    # # ------------------------------------------------
    # # JSON OPTIONS
    # # ------------------------------------------------
    
    # if ff_type == "JSON":
    
    #     st.markdown("### üßæ JSON Settings")
    
    #     strip_array = st.checkbox("STRIP_OUTER_ARRAY", True, key="json_strip")
    #     ignore_utf = st.checkbox("IGNORE_UTF8_ERRORS", True, key="json_utf")
    
    # # ------------------------------------------------
    # # PARQUET OPTIONS
    # # ------------------------------------------------
    
    # if ff_type == "PARQUET":
    
    #     st.markdown("### üß± Parquet Settings")

    #     logical = st.checkbox("USE_LOGICAL_TYPE", True, key="pq_logical")
    #     trim = st.checkbox("TRIM_SPACE", True, key="pq_trim")
    #     type = st.checkbox("TYPE", True, key="pq_type")
    #     compression = st.checkbox("COMPRESSION", True, key="pq_compression")
    #     binary_as_text = st.checkbox("BINARY_AS_TEXT", True, key="pq_binary_as_text")
    #     use_vectorized_scanner = st.checkbox("USE_VECTORIZED_SCANNER", True, key="pq_use_vectorized_scanner")
    #     replace_invalid_characters = st.checkbox("REPLACE_INVALID_CHARACTERS", True, key="pq_replace_invalid_characters")
    #     null_if = st.checkbox("NULL_IF", True, key="pq_null_if")

    
    # # ------------------------------------------------
    # # CREATE FILE FORMAT BUTTON
    # # ------------------------------------------------
    
    # if st.button("üöÄ Create File Format", key="create_ff_btn", type="primary"):
    
    #     full_schema = f"{CONFIG_DB}.{CONFIG_SCHEMA}"
    
    #     try:
    
    #         if ff_type == "CSV":
    
    #             sql = f"""
    # CREATE OR REPLACE FILE FORMAT {full_schema}.{ff_name}
    # TYPE = CSV
    # FIELD_DELIMITER = '{delimiter}'
    # PARSE_HEADER = TRUE
    # ESCAPE_UNENCLOSED_FIELD = 'NONE'
    # TRIM_SPACE = TRUE
    # FIELD_OPTIONALLY_ENCLOSED_BY = '"'
    # NULL_IF = ('NULL','')
    # ERROR_ON_COLUMN_COUNT_MISMATCH = FALSE
    # REPLACE_INVALID_CHARACTERS = TRUE
    # """
    
    #         elif ff_type == "JSON":
    
    #             sql = f"""
    # CREATE OR REPLACE FILE FORMAT {full_schema}.{ff_name}
    # TYPE = JSON
    # STRIP_OUTER_ARRAY = {str(strip_array).upper()}
    # IGNORE_UTF8_ERRORS = {str(ignore_utf).upper()}
    # """
    
    #         else:  # PARQUET
    
    #             sql = f"""
    # CREATE OR REPLACE FILE FORMAT {full_schema}.{ff_name}
    #                 TYPE = 'PARQUET'
    #                 COMPRESSION = 'AUTO'
    #                 -- SNAPPY_COMPRESSION = TRUE
    #                 BINARY_AS_TEXT = FALSE
    #                 USE_LOGICAL_TYPE =  {str(logical).upper()}
    #                 TRIM_SPACE = {str(trim).upper()}
    #                 USE_VECTORIZED_SCANNER = TRUE
    #                 REPLACE_INVALID_CHARACTERS = TRUE
    #                 NULL_IF = ('NULL', 'null', '')"""
    
    #         st.code(sql, language="sql")  # preview
    #         session.sql(sql).collect()
    
    #         st.success(f"‚úÖ File Format `{ff_name}` created")
    
    #     except Exception as e:
    #         st.error(str(e))
    
    # # ============================================================
    # # INFER SCHEMA SQL GENERATOR
    # # ============================================================
    
    # st.markdown("---")
    # st.subheader("üß† Infer Schema SQL Builder")
    
    # stage_path = st.text_input(
    #     "üìÇ Stage Path",
    #     placeholder="@stage/path/",
    #     key="infer_stage"
    # )
    
    # if st.button("üîç Generate Infer Schema SQL", key="infer_sql_btn"):
    
    #     infer_sql = f"""
    # SELECT *
    # FROM TABLE(
    #     INFER_SCHEMA(
    #         LOCATION => '{stage_path}',
    #         FILE_FORMAT => '{CONFIG_DB}.{CONFIG_SCHEMA}.{ff_name}',
    #         MAX_FILE_COUNT => 100
    #     )
    # );
    # """
    
    #     st.code(infer_sql, language="sql")

    
    
    st.markdown("---")
    
    
    options = get_integrations()
    # choice = st.selectbox("Select Integration", options)
    choice = st.selectbox("Select Integration", options, key="step1_integration_select")
    
    
    if st.button("‚û°Ô∏è Continue to CDC Setup", type="primary"):
    
        if choice == "‚ûï Create New":
            st.error("Please select or create integration first")
            st.stop()
    
        st.session_state.storage_integration = choice
        st.session_state.config_db = CONFIG_DB
        st.session_state.config_schema = CONFIG_SCHEMA
        st.session_state.setup_complete = True
    
        st.rerun()
    st.stop()
    




# st.markdown("---")


# options = ["‚ûï Create New"] + get_integrations()
# # choice = st.selectbox("Select Integration", options)
# choice = st.selectbox("Select Integration", options, key="step1_integration_select")

# if st.button("‚û°Ô∏è Next: Go to CDC Setup", key="goto_cdc_btn", type="primary"):

#     if choice == "‚ûï Create New":
#         st.error("Please create or select an integration first")
#         st.stop()

#     st.session_state.storage_integration = choice
#     st.session_state.config_db = CONFIG_DB
#     st.session_state.config_schema = CONFIG_SCHEMA
#     st.session_state.app_step = 2

#     st.rerun()

else:

    def initialize_session_state():
        if 'cdc_configs' not in st.session_state:
            st.session_state.cdc_configs = {}
        if 'active_config' not in st.session_state:
            st.session_state.active_config = None
        if 'log_entries' not in st.session_state:
            st.session_state.log_entries = []
        # if 'setup_complete' not in st.session_state:
        #     st.session_state.setup_complete = st.session_state.get("app_step") == 2
        if 'storage_integration' not in st.session_state:
            st.session_state.storage_integration = None
        if 'config_db' not in st.session_state:
            st.session_state.config_db = None
        if 'config_schema' not in st.session_state:
            st.session_state.config_schema = None
        if 'imported_configs' not in st.session_state:
            st.session_state.imported_configs = []
    
    def log_action(action, status, message, config_name=None):
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        entry = {
            "timestamp": timestamp,
            "action": action,
            "status": status,
            "message": message,
            "config": config_name or (st.session_state.active_config if 'active_config' in st.session_state else None)
        }
        st.session_state.log_entries.append(entry)
    
    # ------------------------------------------------
    # DATABASE AND SCHEMA MANAGEMENT
    # ------------------------------------------------
    
    def check_or_create_database(session, db_name):
        try:
            db_check = session.sql(f"SHOW DATABASES LIKE '{db_name}'").collect()
            if not db_check:
                session.sql(f"CREATE DATABASE IF NOT EXISTS {db_name}").collect()
                log_action("Database Creation", "Success", f"Database {db_name} created")
            return True
        except Exception as e:
            log_action("Database Creation", "Failed", str(e))
            raise
    
    def check_or_create_schema(session, db_name, schema_name):
        try:
            schema_check = session.sql(f"SHOW SCHEMAS LIKE '{schema_name}' IN DATABASE {db_name}").collect()
            if not schema_check:
                session.sql(f"CREATE SCHEMA IF NOT EXISTS {db_name}.{schema_name}").collect()
                log_action("Schema Creation", "Success", f"Schema {db_name}.{schema_name} created")
            return True
        except Exception as e:
            log_action("Schema Creation", "Failed", str(e))
            raise
    
    def get_databases(session):
        try:
            return [db['name'] for db in session.sql("SHOW DATABASES").collect()]
        except Exception as e:
            log_action("Get Databases", "Failed", str(e))
            return []
    
    def get_schemas(session, database):
        try:
            return [s['name'] for s in session.sql(f"SHOW SCHEMAS IN DATABASE {database}").collect()]
        except Exception as e:
            log_action("Get Schemas", "Failed", str(e))
            return []
    
    # # ------------------------------------------------
    # # STORAGE INTEGRATION MANAGEMENT
    # # ------------------------------------------------
    
    # selected_integration = st.session_state.get("storage_integration")
    
    # if not selected_integration or selected_integration == "‚ûï Create New":
    #     st.error("Please create or select an integration first")
    #     st.stop()
    
    
    # def get_storage_integrations(session):
    #     try:
    #         integrations = session.sql("""
    #             SELECT "name" AS NAME FROM CONNECTION_S3.PUBLIC.INTERATION_INFO;
    #         """).collect()
            
    #         return [row['NAME'] for row in integrations] if integrations else []
    #     except Exception as e:
    #         st.error(f"Error fetching storage integrations: {str(e)}")
    #         log_action("Get Integrations", "Failed", str(e))
    #         return []
    
    # def save_integration_to_config(session, name, details):
    #     try:
    #         session.sql(f"""
    #             INSERT INTO CONNECTION_S3.PUBLIC.INTERATION_INFO
    #             (
    #                 NAME,
    #                 STORAGE_PROVIDER,
    #                 STORAGE_ALLOWED_LOCATIONS,
    #                 STORAGE_AWS_IAM_USER_ARN,
    #                 STORAGE_AWS_EXTERNAL_ID
    #             )
    #             VALUES
    #             (
    #                 '{name}',
    #                 '{details["STORAGE_PROVIDER"]}',
    #                 '{details["STORAGE_ALLOWED_LOCATIONS"]}',
    #                 '{details["STORAGE_AWS_IAM_USER_ARN"]}',
    #                 '{details["STORAGE_AWS_EXTERNAL_ID"]}'
    #             )
    #         """).collect()
    
    #         log_action("Config Insert", "Success", f"Inserted {name} into config table")
    
    #     except Exception as e:
    #         log_action("Config Insert", "Failed", str(e))
    #         raise
    
    
            
    
    # def create_storage_integration(session, name, aws_role_arn, allowed_locations):
    #     try:
    #         session.sql(f"""
    #             CREATE STORAGE INTEGRATION IF NOT EXISTS {name}
    #             TYPE = EXTERNAL_STAGE
    #             STORAGE_PROVIDER = 'S3'
    #             ENABLED = TRUE
    #             STORAGE_AWS_ROLE_ARN = '{aws_role_arn}'
    #             STORAGE_ALLOWED_LOCATIONS = ({', '.join(f"'{loc}'" for loc in allowed_locations)})
    #         """).collect()
    #         log_action("Integration Creation", "Success", f"Created storage integration {name}")
    #         return True
    #     except Exception as e:
    #         log_action("Integration Creation", "Failed", str(e))
    #         raise
    
    # def describe_storage_integration(session, name):
    #     try:
    #         df = session.sql(f"DESC STORAGE INTEGRATION {name}").to_pandas()
    #         props = dict(zip(df["property"], df["value"]))
    
    #         return {
    #             "STORAGE_PROVIDER": props.get("STORAGE_PROVIDER"),
    #             "STORAGE_ALLOWED_LOCATIONS": props.get("STORAGE_ALLOWED_LOCATIONS"),
    #             "STORAGE_AWS_IAM_USER_ARN": props.get("STORAGE_AWS_IAM_USER_ARN"),
    #             "STORAGE_AWS_EXTERNAL_ID": props.get("STORAGE_AWS_EXTERNAL_ID")
    #         }
    #     except Exception as e:
    #         st.error(f"Failed to describe integration: {e}")
    #         return None
    
      
    
    # ------------------------------------------------
    # FILE FORMAT MANAGEMENT
    # ------------------------------------------------
    
    def check_or_create_file_format(session, schema, format_name):
        try:
            ff_check = session.sql(f"""
                SELECT * FROM INFORMATION_SCHEMA.FILE_FORMATS 
                WHERE FILE_FORMAT_SCHEMA = '{schema.split('.')[-1]}' 
                AND FILE_FORMAT_NAME = '{format_name}'
            """).collect()
            
            if not ff_check:
                session.sql(f"""
                    CREATE FILE FORMAT IF NOT EXISTS {schema}.{format_name}
                    TYPE = 'PARQUET'
                    COMPRESSION = 'AUTO'
                    -- SNAPPY_COMPRESSION = TRUE
                    BINARY_AS_TEXT = FALSE
                    USE_LOGICAL_TYPE = TRUE
                    TRIM_SPACE = TRUE
                    USE_VECTORIZED_SCANNER = TRUE
                    REPLACE_INVALID_CHARACTERS = TRUE
                    NULL_IF = ('NULL', 'null', '');
                """).collect()
                log_action("File Format Creation", "Success", f"File format {schema}.{format_name} created")
            return True
        except Exception as e:
            log_action("File Format Creation", "Failed", str(e))
            raise
    def get_file_formats(session, database, schema):

        try:
            df = session.sql(f"""
                SELECT FILE_FORMAT_NAME
                FROM {database}.INFORMATION_SCHEMA.FILE_FORMATS
                WHERE FILE_FORMAT_SCHEMA = '{schema}'
                ORDER BY FILE_FORMAT_NAME
            """).to_pandas()
    
            if df.empty:
                return []
    
            return df["FILE_FORMAT_NAME"].tolist()
    
        except:
            return []

    
    # ------------------------------------------------
    # CONFIGURATION TABLE MANAGEMENT
    # ------------------------------------------------
    
    def create_config_table(session, schema):
        try:
            session.sql(f"""
                CREATE  TABLE IF NOT EXISTS {schema}.CDC_CONFIGURATIONS (
                    CONFIG_NAME STRING,
                    SOURCE_URL STRING,
                    PRIMARY_KEY STRING,
                    STAGING_SCHEMA STRING,
                    TARGET_SCHEMA STRING,
                    WAREHOUSE STRING,
                    SCHEDULE STRING,
                    HISTORICAL_COPY BOOLEAN,
                    SNOWPIPE BOOLEAN,
                    STREAM BOOLEAN,
                    TASK_ENABLED BOOLEAN,
                    FILE_FORMAT STRING,
                    DESCRIPTION STRING,
                    CREATED_AT TIMESTAMP_LTZ,
                    LAST_MODIFIED TIMESTAMP_LTZ
                )
            """).collect()
            log_action("Config Table Creation", "Success", f"Configuration table created in {schema}")
            return True
        except Exception as e:
            log_action("Config Table Creation", "Failed", str(e))
            raise
    
    def truncate_config_table(session, schema):
        """Truncate the configuration table"""
        try:
            session.sql(f"TRUNCATE TABLE IF EXISTS {schema}.CDC_CONFIGURATIONS").collect()
            log_action("Config Table Truncation", "Success", f"Configuration table {schema}.CDC_CONFIGURATIONS truncated")
            return True
        except Exception as e:
            log_action("Config Table Truncation", "Failed", str(e))
            raise
    
    def save_config_to_table(session, schema, config_name, config_data):
        try:
            historical_copy = 'TRUE' if config_data['historical_copy'] else 'False'
            snowpipe_enabled = 'TRUE' if config_data.get('snowpipe', False) else 'False'
            stream_enabled = 'TRUE' if config_data.get('stream', False) else 'False'
            task_enabled = 'TRUE' if config_data['task'] else 'False'
            
            session.sql(f"""
                INSERT INTO {schema}.CDC_CONFIGURATIONS (
                    CONFIG_NAME, SOURCE_URL, PRIMARY_KEY, STAGING_SCHEMA, TARGET_SCHEMA,
                    WAREHOUSE, SCHEDULE, HISTORICAL_COPY, SNOWPIPE,STREAM, TASK_ENABLED, FILE_FORMAT,
                    DESCRIPTION, CREATED_AT, LAST_MODIFIED
                ) VALUES (
                    '{config_name}', '{config_data['source_url']}', '{config_data['primary_key']}', 
                    '{config_data['schema']}', '{config_data['gold_schema']}', '{config_data['warehouse']}', 
                    '{config_data['schedule']}', {historical_copy}, {snowpipe_enabled},{stream_enabled}, {task_enabled}, '{config_data['file_format']}',
                    '{config_data['description']}', CURRENT_TIMESTAMP(), CURRENT_TIMESTAMP()
                )
            """).collect()
            log_action("Config Save", "Success", f"Configuration '{config_name}' saved")
            return True
        except Exception as e:
            log_action("Config Save", "Failed", str(e))
            raise
    
    def load_configs_from_table(session, schema):
        try:
            configs = session.sql(f"SELECT * FROM {schema}.CDC_CONFIGURATIONS").collect()
            st.session_state.cdc_configs = {
                config['CONFIG_NAME']: {
                    "source_url": config['SOURCE_URL'],
                    "primary_key": config['PRIMARY_KEY'],
                    "schema": config['STAGING_SCHEMA'],
                    "gold_schema": config['TARGET_SCHEMA'],
                    "warehouse": config['WAREHOUSE'],
                    "schedule": config['SCHEDULE'],
                    "historical_copy": config['HISTORICAL_COPY'],
                    "snowpipe": config.get('SNOWPIPE', False),
                    "stream": config.get('STREAM', False),
                    "task": config['TASK_ENABLED'],
                    "file_format": config['FILE_FORMAT'],
                    "description": config['DESCRIPTION'],
                    "created_at": config['CREATED_AT'],
                    "last_modified": config['LAST_MODIFIED']
                } for config in configs
            }
            log_action("Config Load", "Success", f"Loaded {len(configs)} configurations")
            return True
        except Exception as e:
            log_action("Config Load", "Failed", str(e))
            return False

    def to_bool(v):
        """Convert Excel TRUE/FALSE ‚Üí Python True/False (capitalized)"""
        if v is None:
            return False
        val = str(v).strip().upper()  # TRUE ‚Üí TRUE
        if val == "TRUE":
            return True   # Python True (capitalized)
        elif val in ("1", "YES", "Y"):
            return True
        return False 

    def normalize_config_keys(config):
        """Map Excel UPPERCASE ‚Üí lowercase keys and enforce boolean conversion"""
    
        key_mapping = {
            "HISTORICAL_COPY": "historical_copy",
            "SNOWPIPE": "snowpipe",
            "STREAM": "stream",
            "TASK_ENABLED": "task"
        }
    
        new_config = config.copy()
    
        for excel_key, python_key in key_mapping.items():
    
            value = config.get(excel_key, config.get(python_key, False))
    
            # ---------- Force boolean safely ----------
            if isinstance(value, str):
                value = value.strip().lower() == "true"
    
            new_config[python_key] = bool(value)
    
        return new_config

    
    def run_cdc(session, config_name, config, full_file_format, execution_log):
        """
        Complete CDC Pipeline: Stage ‚Üí Table ‚Üí Stream ‚Üí Gold ‚Üí Snowpipe ‚Üí Task
        """
        config = normalize_config_keys(config) 

        
        use_stream = config["stream"]  
        
        try:
            # Parse names
            base_name = config["source_url"].rstrip('/').split('/')[-1]
            stage_name = f"{base_name}_STAGE"
            stream_name = f"{base_name}_STREAM"
            task_name = f"{base_name}_TASK"
            pipe_name = f"{base_name}_PIPE"
            staging_table = f"{base_name}_STAGING" if use_stream else base_name
            target_table = base_name
            
            # Parse schemas
            if '.' in config['schema']:
                staging_db, staging_schema = config['schema'].split('.', 1)
            else:
                staging_db = st.session_state.config_db
                staging_schema = config['schema']
                
            if '.' in config['gold_schema']:
                target_db, target_schema = config['gold_schema'].split('.', 1)
            else:
                target_db = st.session_state.config_db
                target_schema = config['gold_schema']
            
            # Full qualified names
            config['schema'] = f"{staging_db}.{staging_schema}"
            config['gold_schema'] = f"{target_db}.{target_schema}"
            
            # ------------------------------------------------
            # 2. INFRA CREATION (DB/Schema/Stage)
            # ------------------------------------------------
            check_or_create_database(session, staging_db)
            check_or_create_schema(session, staging_db, staging_schema)
            check_or_create_database(session, target_db)
            check_or_create_schema(session, target_db, target_schema)
            execution_log.append(("Schemas", "Success", f"{config['schema']} ‚Üí {config['gold_schema']}"))


        
            
            # Stage
            session.sql(f"""
                CREATE OR REPLACE STAGE {config['schema']}.{stage_name} 
                URL = '{config['source_url']}' 
                STORAGE_INTEGRATION = {st.session_state.storage_integration}
                FILE_FORMAT = (FORMAT_NAME = '{full_file_format}');
            """).collect()
            execution_log.append(("Stage", "Success", stage_name))
            
            # Staging Table (Infer Schema + Normalize)
            session.sql(f"""
                CREATE OR REPLACE TABLE {config['schema']}.{staging_table} 
                USING TEMPLATE (
                    SELECT ARRAY_AGG(OBJECT_CONSTRUCT(*))
                    FROM TABLE(
                        INFER_SCHEMA(
                            LOCATION => '@{config["schema"]}.{stage_name}',
                            FILE_FORMAT => '{full_file_format}'
                        )
                    )
                )
                WITH ENABLE_SCHEMA_EVOLUTION = TRUE;
            """).collect()
            
            # Normalize NUMBER columns
            cols = session.sql(f"""
                SELECT column_name
                FROM information_schema.columns
                WHERE table_schema = '{staging_schema}' AND table_catalog = '{staging_db}'
                AND table_name = '{staging_table}' AND data_type = 'NUMBER'
            """).collect()
            
            for row in cols:
                session.sql(f"""
                    ALTER TABLE {config['schema']}.{staging_table}
                    ALTER COLUMN {row['COLUMN_NAME']} SET DATA TYPE NUMBER(10,2)
                """).collect()
                
            execution_log.append(("Staging Table", "Success", staging_table))
            
            # ------------------------------------------------
            # 3. TARGET TABLE
            # ------------------------------------------------
            if use_stream:
                session.sql(f"""
                    CREATE TABLE IF NOT EXISTS {config['gold_schema']}.{target_table}
                    LIKE {config['schema']}.{staging_table};
                """).collect()
                execution_log.append(("Target Table", "Success", f"‚úÖ {config['gold_schema']}.{target_table}"))
            else:
                execution_log.append(("Target Table", "Skipped", "STREAM=False"))
            
            # ------------------------------------------------
            # 4. STREAM CREATION
            # ------------------------------------------------
            if use_stream:
                session.sql(f"""
                    CREATE OR REPLACE STREAM {config['schema']}.{stream_name}
                    ON TABLE {config['schema']}.{staging_table}
                    APPEND_ONLY = TRUE;
                """).collect()
                execution_log.append(("Stream", "Success", f"‚úÖ {config['schema']}.{stream_name}"))
            else:
                execution_log.append(("Stream", "Skipped", "STREAM=FALSE"))
            
            # ------------------------------------------------
            # 5. HISTORICAL LOAD
            # ------------------------------------------------
            if config["historical_copy"]:
                session.sql(f"""
                    COPY INTO {config['schema']}.{staging_table} 
                    FROM @{config['schema']}.{stage_name} 
                    FILE_FORMAT = (FORMAT_NAME = '{full_file_format}') 
                    MATCH_BY_COLUMN_NAME = CASE_INSENSITIVE;
                """).collect()
                execution_log.append(("Historical Load", "Success", "‚úÖ Loaded"))
            
            # ------------------------------------------------
            # 6. SNOWPIPE (Only if STREAM enabled)
            # ------------------------------------------------
            if config["snowpipe"] and use_stream:
                full_pipe = f'{config["schema"]}.{pipe_name}'
                session.sql(f"""
                    CREATE OR REPLACE PIPE {full_pipe}
                    AUTO_INGEST = TRUE
                    AS
                    COPY INTO {config['schema']}.{staging_table}
                    FROM @{config['schema']}.{stage_name}
                    FILE_FORMAT = (FORMAT_NAME = '{full_file_format}')
                    MATCH_BY_COLUMN_NAME = CASE_INSENSITIVE;
                """).collect()
                
                # Get notification channel
                df = session.sql(f"DESC PIPE {full_pipe}").to_pandas()
                df.columns = [c.lower() for c in df.columns]
                props = dict(zip(df['property'], df['property_value']))
                notification_channel = props.get("notification_channel", "N/A")
                
                st.session_state.snowpipe_info = st.session_state.get("snowpipe_info", {})
                st.session_state.snowpipe_info[config_name] = {
                    "pipe": full_pipe, "notification": notification_channel
                }
                execution_log.append(("Snowpipe", "Success", f"‚úÖ {full_pipe} | Channel: {notification_channel}"))
            else:
                execution_log.append(("Snowpipe", "Skipped", "snowpipe=FALSE or STREAM=FALSE"))
            
            # ------------------------------------------------
            # 7. TASK + MERGE (Only if STREAM + TASK enabled)
            # ------------------------------------------------
            if config["task"] and use_stream:
                db_name, schema_name = config['schema'].split('.', 1)
                
                # Get columns (exclude metadata)
                columns_df = session.sql(f"""
                    SELECT COLUMN_NAME 
                    FROM {db_name}.INFORMATION_SCHEMA.COLUMNS
                    WHERE LOWER(TABLE_SCHEMA) = LOWER('{schema_name}')
                    AND LOWER(TABLE_NAME) = LOWER('{staging_table}')
                    AND COLUMN_NAME NOT LIKE 'METADATA$%'
                """).collect()
                
                column_names = [col['COLUMN_NAME'] for col in columns_df]
                column_list = ", ".join(column_names)
                update_list = ", ".join([f"TARGET.{col} = STAGED.{col}" for col in column_names])
                
                primary_keys = [k.strip() for k in config["primary_key"].split(",")]
                partition_clause = ", ".join(primary_keys)
                on_clause = " AND ".join([f"TARGET.{k} = STAGED.{k}" for k in primary_keys])
                
                merge_sql = f"""
                MERGE INTO {config['gold_schema']}.{target_table} AS TARGET 
                USING (
                    SELECT {column_list}, METADATA$ACTION
                    FROM {config['schema']}.{stream_name}
                    WHERE METADATA$ACTION IN ('INSERT', 'DELETE')
                    QUALIFY ROW_NUMBER() OVER (
                        PARTITION BY {partition_clause}
                        ORDER BY CASE METADATA$ACTION WHEN 'DELETE' THEN 1 ELSE 2 END DESC
                    ) = 1
                ) AS STAGED 
                ON {on_clause}
                WHEN MATCHED AND STAGED.METADATA$ACTION = 'DELETE' THEN DELETE 
                WHEN MATCHED AND STAGED.METADATA$ACTION = 'INSERT' THEN UPDATE SET {update_list}
                WHEN NOT MATCHED AND STAGED.METADATA$ACTION = 'INSERT' THEN 
                    INSERT ({column_list}) VALUES ({column_list});
                """
                
                session.sql(f"""
                    CREATE OR REPLACE TASK {config['schema']}.{task_name}
                    WAREHOUSE = '{config['warehouse']}'
                    SCHEDULE = '{config['schedule']}'
                    AS {merge_sql}
                """).collect()
                
                session.sql(f"ALTER TASK {config['schema']}.{task_name} RESUME").collect()
                execution_log.append(("Task", "Success", f"‚úÖ {config['schema']}.{task_name} resumed"))
            else:
                execution_log.append(("Task", "Skipped", "task=FALSE or STREAM=FALSE"))
            
            log_action("CDC Pipeline", "Success", f"‚úÖ Complete: {config_name}", config_name)
            
        except Exception as e:
            error_msg = f"‚ùå {config_name}: {str(e)}"
            st.error(error_msg)
            log_action("CDC Pipeline", "Failed", error_msg, config_name)
            execution_log.append(("Pipeline", "Failed", error_msg))


            
    # def to_bool(v):
    #     return str(v).strip().lower() in ("true", "1", "yes", "y")
    
    # ------------------------------------------------
    # MAIN CDC EXECUTION LOGIC
    # ------------------------------------------------

    # snowpipe_result = None
    
#     def run_cdc(session, config_name, config, full_file_format, execution_log):

#         config["historical_copy"] = to_bool(config.get("HISTORICAL_COPY", config.get("historical_copy")))
#         config["snowpipe"] = to_bool(config.get("SNOWPIPE", config.get("snowpipe")))
#         config["stream"] = to_bool(config.get("STREAM", config.get("stream")))  # Convert here
#         config["task"] = to_bool(config.get("TASK_ENABLED", config.get("task")))
#         use_stream = config["stream"]
#         try:
#             base_name = config["source_url"].rstrip('/').split('/')[-1]
            
#             if use_stream:
#                 table_name = f"{base_name}_STAGING"
#             else:
#                 table_name = base_name   # direct table (no staging suffix)
            
#             stage_name = f"{base_name}_STAGE"
#             stream_name = f"{base_name}_STREAM"
#             task_name = f"{base_name}_TASK"
#             pipe_name = f"{base_name}_PIPE"
#             target_table = base_name


    
#             if '.' in config['schema']:
#                 staging_db, staging_schema = config['schema'].split('.', 1)
#             else:
#                 staging_db = st.session_state.config_db
#                 staging_schema = config['schema']
            
#             if '.' in config['gold_schema']:
#                 target_db, target_schema = config['gold_schema'].split('.', 1)
#             else:
#                 target_db = st.session_state.config_db
#                 target_schema = config['gold_schema']
    
#             # Validate Schemas
#             check_or_create_database(session, staging_db)
#             check_or_create_schema(session, staging_db, staging_schema)
#             check_or_create_database(session, target_db)
#             check_or_create_schema(session, target_db, target_schema)

#             # config["historical_copy"] = to_bool(config.get("HISTORICAL_COPY", config.get("historical_copy")))
#             # config["snowpipe"]        = to_bool(config.get("SNOWPIPE", config.get("snowpipe")))
#             # config["stream"]          = to_bool(config.get("STREAM", config.get("stream")))
#             # config["task"]            = to_bool(config.get("TASK_ENABLED", config.get("task")))


    
#             config['schema'] = f"{staging_db}.{staging_schema}"
#             config['gold_schema'] = f"{target_db}.{target_schema}"
#             execution_log.append(("Schema Validation", "Success", f"{config['schema']} and {config['gold_schema']} verified"))
    
#             # Create Stage
#             session.sql(f"""
#                 CREATE OR REPLACE STAGE {config['schema']}.{stage_name} 
#                 URL = '{config['source_url']}' 
#                 STORAGE_INTEGRATION = {st.session_state.storage_integration}
#                 FILE_FORMAT = (FORMAT_NAME = '{full_file_format}');
#             """).collect()
#             execution_log.append(("Stage Creation", "Success", f"Created stage: {config['schema']}.{stage_name}"))
            
#             # Create Tables
#             session.sql(f"""
#                 CREATE OR REPLACE TABLE {config['schema']}.{table_name} 
#                 USING TEMPLATE (
#                     SELECT ARRAY_AGG(OBJECT_CONSTRUCT(*))
#                     FROM TABLE(
#                         INFER_SCHEMA(
#                             LOCATION => '@{config["schema"]}.{stage_name}',
#                             FILE_FORMAT => '{full_file_format}'
#                         )
#                     )
#                 )
#                 WITH ENABLE_SCHEMA_EVOLUTION = TRUE;
#             """).collect()
#             execution_log.append(("Staging Table", "Success", f"Created {config['schema']}.{table_name}"))
    
#             normalize_sql = f"""
#             SELECT column_name
#             FROM information_schema.columns
#             WHERE table_schema = '{config['schema']}'
#             AND table_name = '{table_name}'
#             AND data_type = 'NUMBER'
#             """
#             cols = session.sql(normalize_sql).collect()
            
#             for row in cols:
#                 session.sql(f"""
#                     ALTER TABLE {config['schema']}.{table_name}
#                     ALTER COLUMN {row['COLUMN_NAME']} SET DATA TYPE NUMBER(10,2)
#                 """).collect()
    
#             # session.sql(f"""
#             #     CREATE TABLE IF NOT EXISTS {config['gold_schema']}.{target_table} 
#             #     LIKE {config['schema']}.{table_name};
#             # """).collect()
#             # execution_log.append(("Target Table", "Success", f"Created {config['gold_schema']}.{target_table}"))
#             # use_stream = config["stream"]
            
#             if use_stream:
#                 session.sql(f"""
#                 CREATE TABLE IF NOT EXISTS {config['gold_schema']}.{target_table}
#                 LIKE {config['schema']}.{table_name};
#                 """).collect()
            
#                 execution_log.append((
#                     "Target Table",
#                     "Success",
#                     f"Created {config['gold_schema']}.{target_table}"
#                 ))
#             else:
#                 execution_log.append((
#                     "Target Table",
#                     "Skipped",
#                     "STREAM flag = FALSE"
#                 ))

# #---------------------STREAM CREATION--------------------

#             if use_stream:
#                 session.sql(f"""
#                     CREATE OR REPLACE STREAM {config['schema']}.{stream_name}
#                     ON TABLE {config['schema']}.{table_name};
#                 """).collect()
            
#                 execution_log.append((
#                     "Stream Creation",
#                     "Success",
#                     f"{config['schema']}.{stream_name}"
#                 ))
            
#             else:
            
#                 execution_log.append((
#                     "Stream Creation",
#                     "Skipped",
#                     "STREAM flag = FALSE"
#                 ))

#     ######------HISTORICAL LOAD---------##################
#             # Historical Load
#             if config["historical_copy"]:
#                 session.sql(f"""
#                     COPY INTO {config['schema']}.{table_name} 
#                     FROM @{config['schema']}.{stage_name} 
#                     FILE_FORMAT = (FORMAT_NAME = '{full_file_format}') 
#                     MATCH_BY_COLUMN_NAME = CASE_INSENSITIVE;
#                 """).collect()
#                 execution_log.append(("Historical Load", "Success", "Completed historical data load"))
    
#             # ------------------------------------------------
#             # SNOWPIPE CREATION LOGIC - NEW ADDITION
#             # ------------------------------------------------
#             # if config.get("snowpipe", False):
#             #     try:
#             #         session.sql(f"""
#             #             CREATE OR REPLACE PIPE {config['schema']}.{pipe_name} 
#             #             AUTO_INGEST = TRUE 
#             #             AS 
#             #             COPY INTO {config['schema']}.{table_name} 
#             #             FROM @{config['schema']}.{stage_name}  
#             #             FILE_FORMAT = (FORMAT_NAME = '{full_file_format}') 
#             #             MATCH_BY_COLUMN_NAME = CASE_INSENSITIVE;
#             #         """).collect()
#             #         execution_log.append(("Snowpipe Creation", "Success", f"Created Snowpipe: {config['schema']}.{pipe_name}"))
#             #         log_action("Snowpipe Creation", "Success", f"Snowpipe {pipe_name} created for {config_name}", config_name)
                    
#             #         # Get Snowpipe notification channel for S3 event configuration
#             #         try:
#             #             pipe_status = session.sql(f"DESC PIPE {config['schema']}.{pipe_name}").collect()
#             #             notification_channel = None
#             #             for row in pipe_status:
#             #                 if row['property'] == 'notification_channel':
#             #                     notification_channel = row['property_value']
#             #                     break
                        
#             #             if notification_channel:
#             #                 execution_log.append(("Snowpipe Info", "Success", 
#             #                     f"Notification Channel: {notification_channel}. Configure this in your S3 bucket event notifications."))
#             #         except Exception as e:
#             #             execution_log.append(("Snowpipe Info", "Warning", 
#             #                 f"Could not retrieve notification channel: {str(e)}"))
                    
#             #     except Exception as e:
#             #         log_action("Snowpipe Creation", "Failed", f"Failed to create Snowpipe: {str(e)}", config_name)
#             #         execution_log.append(("Snowpipe Creation", "Failed", f"Snowpipe creation failed: {str(e)}"))
                
#              # ------------------------------------------------
#             # SNOWPIPE SECTION ‚Äî CORRECT VERSION
#             # ------------------------------------------------


#             if config.get("snowpipe", False) and use_stream:
            
#                 full_pipe = f'{config["schema"]}.{pipe_name}'
            
#                 try:
            
#                     session.sql(f"""
#                         CREATE OR REPLACE PIPE {full_pipe}
#                         AUTO_INGEST = TRUE
#                         AS
#                         COPY INTO {config['schema']}.{table_name}
#                         FROM @{config['schema']}.{stage_name}
#                         FILE_FORMAT = (FORMAT_NAME = '{full_file_format}')
#                         MATCH_BY_COLUMN_NAME = CASE_INSENSITIVE;
#                     """).collect()
            
#                     execution_log.append(("Snowpipe Creation","Success",full_pipe))
            
#                     df = session.sql(f"DESC PIPE {full_pipe}").to_pandas()
            
#                     notification_channel = None
#                     copy_stmt = None
            
#                     if not df.empty:
            
#                         df.columns = [c.lower() for c in df.columns]
            
#                         prop_col = next((c for c in df.columns if "property" in c or c=="name"), None)
#                         val_col = next((c for c in df.columns if "value" in c), None)
            
#                         if prop_col and val_col:
#                             props = dict(zip(df[prop_col], df[val_col]))
#                             notification_channel = props.get("notification_channel")
#                             copy_stmt = props.get("definition")
            
#                     if "snowpipe_info" not in st.session_state:
#                         st.session_state.snowpipe_info = {}
            
#                     st.session_state.snowpipe_info[config_name] = {
#                         "pipe": full_pipe,
#                         "notification": notification_channel,
#                         "definition": copy_stmt
#                     }
            
#                     snowpipe_result = {
#                         "pipe": full_pipe,
#                         "notification": notification_channel
#                     }
            
#                 except Exception as e:
            
#                     st.error(f"Snowpipe error ‚Üí {e}")
            
#                     execution_log.append(("Snowpipe Creation","Failed",str(e)))
            
#             else:
#                 execution_log.append(("Snowpipe","Skipped","Flag False or STREAM disabled"))


#             # ------------------------------------------------
#             # END OF SNOWPIPE CREATION LOGIC
#             # ------------------------------------------------
    
#             # Create Task with MERGE logic
#             # if config["task"]:
#             if config["task"] and use_stream:
#                 db_name, schema_name = config['schema'].split('.', 1)
    
#                 columns_df = session.sql(f"""
#                     SELECT COLUMN_NAME 
#                     FROM {db_name}.INFORMATION_SCHEMA.COLUMNS
#                     WHERE LOWER(TABLE_SCHEMA) = LOWER('{schema_name}')
#                     AND LOWER(TABLE_NAME) = LOWER('{table_name}')
#                     AND COLUMN_NAME NOT LIKE 'METADATA$%'
#                 """).collect()
    
#                 if not columns_df:
#                     desc = session.sql(f"DESC TABLE {config['schema']}.{table_name}").collect()
#                     columns_df = [row for row in desc if not row['name'].startswith('METADATA$')]
#                     column_names = [row['name'] for row in columns_df]
#                 else:
#                     column_names = [col['COLUMN_NAME'] for col in columns_df]
    
#                 if not column_names:
#                     raise ValueError("No columns found for MERGE operation")
    
#                 column_list = ", ".join(column_names)
#                 update_list = ", ".join([f"TARGET.{col} = STAGED.{col}" for col in column_names])
    
#                 primary_keys = [k.strip() for k in config["primary_key"].split(",")]
#                 partition_clause = ", ".join(primary_keys)
#                 on_clause = " AND ".join([f"TARGET.{k} = STAGED.{k}" for k in primary_keys])
    
#                 merge_sql = f"""
#                 MERGE INTO {config['gold_schema']}.{target_table} AS TARGET 
#                 USING (
#                     SELECT {column_list}, METADATA$ACTION
#                     FROM {config['schema']}.{stream_name}
#                     WHERE METADATA$ACTION IN ('INSERT', 'DELETE')
#                     QUALIFY ROW_NUMBER() OVER (
#                         PARTITION BY {partition_clause}
#                         ORDER BY CASE METADATA$ACTION WHEN 'DELETE' THEN 1 ELSE 2 END DESC
#                     ) = 1
#                 ) AS STAGED 
#                 ON {on_clause}
#                 WHEN MATCHED AND STAGED.METADATA$ACTION = 'DELETE' THEN DELETE 
#                 WHEN MATCHED AND STAGED.METADATA$ACTION = 'INSERT' THEN UPDATE SET {update_list}
#                 WHEN NOT MATCHED AND STAGED.METADATA$ACTION = 'INSERT' THEN 
#                     INSERT ({column_list}) VALUES ({column_list});
#                 """
    
#                 session.sql(f"""
#                     CREATE OR REPLACE TASK {config['schema']}.{task_name}
#                     WAREHOUSE = '{config['warehouse']}'
#                     SCHEDULE = '{config['schedule']}'
#                     AS
#                     {merge_sql}
#                 """).collect()
    
#                 session.sql(f"ALTER TASK {config['schema']}.{task_name} RESUME").collect()
#                 execution_log.append(("Task Creation", "Success", f"Created and resumed task: {config['schema']}.{task_name}"))
            
#             log_action("CDC Execution", "Success", f"Completed for {config_name}", config_name)
            

    
#         except Exception as e:
#             log_action("CDC Execution", "Failed", f"{config_name} failed: {str(e)}", config_name)
#             execution_log.append(("Execution Failed", "Failed", f"{config_name}: {str(e)}"))
    
    # ------------------------------------------------
    # END OF MAIN CDC EXECUTION LOGIC
    # ------------------------------------------------
    
    def main():
    
        CONFIG_DB = st.session_state.get("config_db")
        CONFIG_SCHEMA = st.session_state.get("config_schema")
    
        if not CONFIG_DB or not CONFIG_SCHEMA:
            st.error("Setup not completed ‚Äî config DB/schema missing")
            st.stop()
    
        if st.button("‚¨ÖÔ∏è Back to Storage Integration"):
            st.session_state.setup_complete = False
            st.rerun()

    
        
        st.markdown("""
        <style>
            .stApp { background-color: #f8f9fa; }
            .header { color: #2c3e50; font-weight: 600; }
            .info-box { background-color: #e8f4f8; padding: 20px; border-radius: 10px; margin-bottom: 20px; border-left: 4px solid #3498db; }
            .success-box { background-color: #e8f8f0; padding: 20px; border-radius: 10px; margin-bottom: 20px; border-left: 4px solid #28a745; }
            .error-box { background-color: #f8e8e8; padding: 20px; border-radius: 10px; margin-bottom: 20px; border-left: 4px solid #dc3545; }
            .warning-box { background-color: #fff3cd; padding: 20px; border-radius: 10px; margin-bottom: 20px; border-left: 4px solid #ffc107; }
            .section { margin-bottom: 30px; border-bottom: 1px solid #eee; padding-bottom: 20px; }
            .stButton>button { background-color: #4CAF50; color: white; font-weight: 500; border-radius: 8px; padding: 10px 24px; border: none; transition: all 0.3s; }
            .stButton>button:hover { background-color: #45a049; box-shadow: 0 4px 8px rgba(0,0,0,0.2); }
            .secondary-button>button { background-color: #6c757d; color: white; }
            .secondary-button>button:hover { background-color: #5a6268; }
            .tab-content { padding: 20px; background-color: white; border-radius: 10px; box-shadow: 0 2px 4px rgba(0,0,0,0.1); }
            .object-card { background-color: white; border-radius: 8px; padding: 20px; margin-bottom: 15px; box-shadow: 0 2px 4px rgba(0,0,0,0.1); transition: all 0.3s; }
            .object-card:hover { box-shadow: 0 4px 8px rgba(0,0,0,0.15); }
            .object-title { font-weight: bold; font-size: 1.1em; margin-bottom: 10px; color: #2c3e50; }
            .status-active { color: #28a745; font-weight: bold; }
            .status-inactive { color: #dc3545; font-weight: bold; }
            .status-warning { color: #ffc107; font-weight: bold; }
            .config-badge { background-color: #e3f2fd; padding: 5px 12px; border-radius: 15px; display: inline-block; margin: 5px; font-size: 0.9em; }
            .metric-card { background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); color: white; padding: 20px; border-radius: 10px; text-align: center; }
            .metric-value { font-size: 2em; font-weight: bold; }
            .metric-label { font-size: 0.9em; opacity: 0.9; }
        </style>
        """, unsafe_allow_html=True)
        
        initialize_session_state()
        session = get_active_session()
        
        st.markdown("<h1 class='header'>üîÑ Snowflake CDC Management Console</h1>", unsafe_allow_html=True)
        st.markdown("""
        <div class='info-box'>
            <strong>üìä Change Data Capture (CDC) Configuration and Monitoring</strong><br>
            Configure, execute, and monitor CDC processes for multiple data sources in Snowflake.
            Set up staging tables, streams, Snowpipes, and automated tasks to keep your data synchronized.
        </div>
        """, unsafe_allow_html=True)
    
        # Initial Setup Wizard
        if not st.session_state.setup_complete:
            with st.expander("‚öôÔ∏è Initial Setup Wizard", expanded=True):
                st.markdown("### üîß Environment Configuration")
                
                # # Storage Integration Section
                # existing_integrations = get_storage_integrations(session)
                # integration_choice = st.radio(
                #     "üì¶ Storage Integration",
                #     ["Use Existing", "Create New"],
                #     index=0 if existing_integrations else 1,
                #     help="Select an existing storage integration or create a new one"
                # )
                
                # if integration_choice == "Use Existing":
                #     if existing_integrations:
                #         selected_integration = st.selectbox(
                #             "Select Storage Integration",
                #             existing_integrations
                #         )
                #     else:
                #         st.warning("‚ö†Ô∏è No existing integrations found. Please create a new one.")
                #         integration_choice = "Create New"
                # else:
                #     new_integration_name = st.text_input("New Integration Name", value="CDC_S3_INTEGRATION")
                #     aws_role_arn = st.text_input("AWS Role ARN", 
                #                                 placeholder="arn:aws:iam::123456789012:role/my-snowflake-role")
                #     allowed_locations = st.text_area("Allowed S3 Paths (one per line)", 
                #                                    value="s3://my-bucket/cdc-data/").split('\n')
                
                # Database Configuration
                st.markdown("### üíæ Database Configuration")
                existing_dbs = get_databases(session)
                db_choice = st.radio("Database", ["Use Existing", "Create New"], index=0 if existing_dbs else 1)
                
                selected_db = None
                if db_choice == "Use Existing":
                    selected_db = st.selectbox("Select Database", existing_dbs)
                else:
                    new_db_name = st.text_input("New Database Name", value="CDC_DATA")
                    selected_db = new_db_name
                
                # Schema Configuration
                st.markdown("### üìÅ Schema Configuration")
                schema_choice = st.radio("Schema", ["Use Existing", "Create New"])
                
                selected_schema = None
                if schema_choice == "Use Existing":
                    if selected_db:
                        existing_schemas = get_schemas(session, selected_db)
                        if existing_schemas:
                            selected_schema = st.selectbox("Select Schema", existing_schemas)
                        else:
                            st.warning("‚ö†Ô∏è No schemas found in selected database. Please create a new one.")
                            schema_choice = "Create New"
                else:
                    new_schema_name = st.text_input("New Schema Name", value="CONFIG")
                    selected_schema = new_schema_name
        
                col1, col2 = st.columns(2)
                with col1:
                    if st.button("‚úÖ Validate File Format", use_container_width=True):
                        try:
                            check_or_create_file_format(
                                session,
                                f"{selected_db}.{selected_schema}",
                                "CDC_FORMAT"
                            )
                            st.success("‚úÖ File format validated/created successfully!")
                        except Exception as e:
                            st.error(f"‚ùå File format error: {str(e)}")
                
                with col2:
                    if st.button("üöÄ Complete Setup", use_container_width=True):
                        with st.spinner("Configuring environment..."):
                            try:
                                # if integration_choice == "Create New":
                                #     create_storage_integration(session, new_integration_name, aws_role_arn, allowed_locations)
                                #     selected_integration = new_integration_name
                                
                                if db_choice == "Create New":
                                    check_or_create_database(session, new_db_name)
                                    selected_db = new_db_name
                                
                                if schema_choice == "Create New":
                                    check_or_create_schema(session, selected_db, new_schema_name)
                                    selected_schema = new_schema_name
                                elif not selected_schema and schema_choice == "Use Existing":
                                    raise ValueError("No schema selected")
                                
                                check_or_create_file_format(
                                    session,
                                    f"{selected_db}.{selected_schema}",
                                    "CDC_FORMAT"
                                )
                                create_config_table(session, f"{selected_db}.{selected_schema}")
                                load_configs_from_table(session, f"{selected_db}.{selected_schema}")
                                
                                st.session_state.setup_complete = True
                                st.session_state.config_db = selected_db
                                st.session_state.config_schema = selected_schema
                                st.session_state.storage_integration = selected_integration
                                
                                st.success("‚úÖ Setup completed successfully!")
                                st.rerun()
                                
                            except Exception as e:
                                st.error(f"‚ùå Setup failed: {str(e)}")
    
        #---- Skip config UI ‚Äî require values from step 1 ----
    
        required = ["storage_integration", "config_db", "config_schema"]
        
        missing = [k for k in required if not st.session_state.get(k)]
        
        if missing:
            st.error("‚ùå Storage setup not completed. Please run Step-1 first.")
            st.stop()
        
        st.session_state.setup_complete = True
    
        
        if not st.session_state.setup_complete:
            st.warning("‚ö†Ô∏è Please complete the initial setup to continue")
            return
        # --------------------------------
        #Config table creation
        #--------------------------------
        create_config_table(session, f"{selected_db}.{selected_schema}")
         load_configs_from_table(session, f"{selected_db}.{selected_schema}")
    

        # -------------------------------
        # Dashboard Metrics
        # -------------------------------
        
        total_configs = len(st.session_state.get("cdc_configs", {}))
        imported_configs = len(st.session_state.get("imported_configs", []))
        
        active_tasks = sum(
            1 for cfg in st.session_state.get("cdc_configs", {}).values()
            if cfg.get("task", False)
        )
        
        col1, col2, col3 = st.columns(3)
        
        col1.metric(
            label="üì¶ Total Configurations",
            value=total_configs,
            help="Total CDC configurations created in this session"
        )
        
        col2.metric(
            label="üì• Imported Configurations",
            value=imported_configs,
            help="Configs loaded from Excel import"
        )
        
        col3.metric(
            label="‚ö° Active Tasks Enabled",
            value=active_tasks,
            help="Configurations where Snowflake TASK is enabled"
        )

        # col1, col2, col3 = st.columns(3)
        # with col1:
        #     st.markdown(f"""
        #     <div class='metric-card'>
        #         <div class='metric-value'>{len(st.session_state.cdc_configs)}</div>
        #         <div class='metric-label'>Total Configurations</div>
        #     </div>
        #     """, unsafe_allow_html=True)
        # with col2:
        #     st.markdown(f"""
        #     <div class='metric-card' style='background: linear-gradient(135deg, #f093fb 0%, #f5576c 100%);'>
        #         <div class='metric-value'>{len(st.session_state.imported_configs)}</div>
        #         <div class='metric-label'>Imported Configs</div>
        #     </div>
        #     """, unsafe_allow_html=True)
        # with col3:
        #     active_tasks = sum(1 for cfg in st.session_state.cdc_configs.values() if cfg.get('task', False))
        #     st.markdown(f"""
        #     <div class='metric-card' style='background: linear-gradient(135deg, #4facfe 0%, #00f2fe 100%);'>
        #         <div class='metric-value'>{active_tasks}</div>
        #         <div class='metric-label'>Active Tasks</div>
        #     </div>
        #     """, unsafe_allow_html=True)
    
        # Main Interface
        tab1, tab2, tab3, tab4, tab5, tab6, tab7 ,tab8 = st.tabs(["‚öôÔ∏è Configuration" , "üßæ File Format", "üì• Import", "‚ñ∂Ô∏è Execution", "üßä Snowpipe","üéØ Single Table", "üìä Monitoring", "üìù Logs"])

        with tab1:
            st.markdown("<h2 class='header'>‚öôÔ∏è CDC Configuration Management</h2>", unsafe_allow_html=True)
            
            # Database/Schema Selection
            col_db, col_schema = st.columns(2)
            with col_db:
                databases = get_databases(session)
                try:
                    db_index = databases.index(st.session_state.config_db)
                except ValueError:
                    db_index = 0
                    st.session_state.config_db = databases[0] if databases else ""
                
                selected_db = st.selectbox("üíæ Database", databases, index=db_index)
            
            with col_schema:
                schemas = get_schemas(session, selected_db)
                try:
                    schema_index = schemas.index(st.session_state.config_schema)
                except ValueError:
                    schema_index = 0
                    st.session_state.config_schema = schemas[0] if schemas else ""
                
                selected_schema = st.selectbox("üìÅ Config Schema", schemas, index=schema_index) 
    
            # def get_schemas(session, database):
            #     try:
            #         return [s['name'] for s in session.sql(f"SHOW SCHEMAS IN DATABASE {database}").collect()]
            #     except Exception as e:
            #         log_action("Get Schemas", "Failed", str(e))
            #         return []
    
                    # ------------------------------------------------
            # STORAGE INTEGRATION FETCH (RESTORED)
            # ------------------------------------------------
            
            def get_storage_integrations(session):
                try:
                    df = session.sql(f"""
                        SELECT NAME
                        FROM {st.session_state.config_db}.{st.session_state.config_schema}.INTERATION_INFO
                        ORDER BY CREATED_ON DESC
                    """).to_pandas()
            
                    if df.empty:
                        return []
            
                    return df["NAME"].tolist()
            
                except Exception as e:
                    log_action("Get Integrations", "Failed", str(e))
                    return []
    
    
            
            # Storage Integration
            integrations = get_storage_integrations(session)
            selected_integration = st.selectbox("üì¶ Storage Integration", integrations, 
                                              index=integrations.index(st.session_state.storage_integration))
        
            st.session_state.config_db = selected_db
            st.session_state.config_schema = selected_schema
            st.session_state.storage_integration = selected_integration
        
            # Configuration Management
            st.markdown("---")
            col1, col2 = st.columns([3, 1])
            with col1:
                config_name = st.text_input("üìù Configuration Name", help="Unique name for this CDC configuration", placeholder="Enter configuration name...")
            with col2:
                st.markdown("<br>", unsafe_allow_html=True)
                if st.button("‚ûï Create New Config", use_container_width=True):
                    if config_name and config_name not in st.session_state.cdc_configs:
                        st.session_state.cdc_configs[config_name] = {
                            "source_url": "",
                            "primary_key": "",
                            "schema": "SILVER",
                            "gold_schema": "GOLD",
                            "warehouse": "COMPUTE_WH",
                            "schedule": "USING CRON 0 * * * * UTC",
                            "historical_copy": True,
                            "snowpipe": False,
                            "task": True,
                            "file_format": "CDC_FORMAT",
                            "description": "",
                            "created_at": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                            "last_modified": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                        }
                        st.session_state.active_config = config_name
                        st.success(f"‚úÖ Configuration '{config_name}' created")
        
            if st.session_state.cdc_configs:
                selected_config = st.selectbox("üìã Select Configuration", list(st.session_state.cdc_configs.keys()))
                config = st.session_state.cdc_configs[selected_config]
                
                with st.form(key="config_form"):
                    col1, col2 = st.columns(2)
                    with col1:
                        config["source_url"] = st.text_input("üîó Source S3 Path", config["source_url"], placeholder="s3://bucket/path/")
                        config["primary_key"] = st.text_input("üîë Primary Key", config["primary_key"], placeholder="ID or ID,TIMESTAMP")
                        
                        # Staging Schema selection
                        staging_schemas = get_schemas(session, selected_db)
                        try:
                            staging_index = staging_schemas.index(config["schema"])
                        except ValueError:
                            staging_index = 0
                        new_staging_schema = st.selectbox(
                            "üìÇ Staging Schema", 
                            staging_schemas, 
                            index=staging_index,
                            key="staging_schema_select"
                        )
                        st.session_state.selected_staging_schema = new_staging_schema
                    
                    with col2:
                        # Target Schema selection
                        target_schemas = get_schemas(session, selected_db)
                        try:
                            target_index = target_schemas.index(config["gold_schema"])
                        except ValueError:
                            target_index = 0
                        new_target_schema = st.selectbox(
                            "üéØ Target Schema", 
                            target_schemas, 
                            index=target_index,
                            key="target_schema_select"
                        )
                        st.session_state.selected_target_schema = new_target_schema
                        
                        config["warehouse"] = st.text_input("üè≠ Warehouse", config["warehouse"], placeholder="COMPUTE_WH")
                        config["schedule"] = st.text_input("‚è∞ Task Schedule", config["schedule"], placeholder="USING CRON 0 * * * * UTC")
                    
                    config["description"] = st.text_area("üìÑ Description", config["description"], placeholder="Describe this CDC configuration...")
                    
                    col_check1, col_check2, col_check3 = st.columns(3)
                    with col_check1:
                        config["historical_copy"] = st.checkbox("üì¶ Initial Historical Load", config["historical_copy"])
                    with col_check2:
                        config["snowpipe"] = st.checkbox("üîÑ Enable Snowpipe", config.get("snowpipe", False))
                    with col_check3:
                        config["task"] = st.checkbox("‚ö° Enable Scheduled Task", config["task"])
        
                    if st.form_submit_button("üíæ Save Configuration", use_container_width=True):
                        try:
                            selected_db = st.session_state.config_db
                            config["schema"] = f"{selected_db}.{st.session_state.selected_staging_schema}"
                            config["gold_schema"] = f"{selected_db}.{st.session_state.selected_target_schema}"
                            
                            save_config_to_table(session, f"{selected_db}.{selected_schema}", selected_config, config)
                            st.success("‚úÖ Configuration saved successfully!")
                        except Exception as e:
                            st.error(f"‚ùå Save failed: {str(e)}")
        
                # Schema creation buttons OUTSIDE the form
                col_create_schemas = st.columns(2)
                with col_create_schemas[0]:
                    if st.button("‚ûï Create Staging Schema", use_container_width=True):
                        schema_name = st.session_state.selected_staging_schema
                        if schema_name not in get_schemas(session, selected_db):
                            check_or_create_schema(session, selected_db, schema_name)
                            st.success(f"‚úÖ Staging schema '{schema_name}' created!")
                            st.rerun()
                
                with col_create_schemas[1]:
                    if st.button("‚ûï Create Target Schema", use_container_width=True):
                        schema_name = st.session_state.selected_target_schema
                        if schema_name not in get_schemas(session, selected_db):
                            check_or_create_schema(session, selected_db, schema_name)
                            st.success(f"‚úÖ Target schema '{schema_name}' created!")
                            st.rerun()

        with tab2:
            st.markdown("---")
            st.subheader("üìÇ File Format Builder")
            
            colf1, colf2 = st.columns(2)
            
            with colf1:
                ff_name = st.text_input(
                    "File Format Name",
                    value="CDC_FORMAT",
                    key="ff_name_input"
                )
            
            with colf2:
                ff_type = st.selectbox(
                    "üìÑ File Type",
                    ["CSV", "JSON", "PARQUET"],
                    key="ff_type_select"
                )
            
            # ------------------------------------------------
            # CSV OPTIONS (Your Required Defaults)
            # ------------------------------------------------
            
            if ff_type == "CSV":
            
                st.markdown("### üìÑ CSV Format Settings")
            
                # delimiter = st.text_input("Delimiter", ",", key="csv_delim")
                parse_header = st.checkbox("PARSE_HEADER", True, key="csv_parse_header")
                trim_space = st.checkbox("TRIM_SPACE", True, key="csv_trim")
                replace_invalid = st.checkbox("REPLACE_INVALID_CHARACTERS", True, key="csv_replace")
                escape_unenclosed_field = st.checkbox("ESCAPE_UNENCLOSED_FIELD", True, key="csv_escape_unenclosed_field")
                field_optionally_enclosed_by = st.checkbox("FIELD_OPTIONALLY_ENCLOSED_BY", True, key="csv_field_optionally_enclosed_by")
                error_on_column_count_mismatch = st.checkbox("ERROR_ON_COLUMN_COUNT_MISMATCH", True, key="csv_error_on_column_count_mismatch")
                null_if = st.checkbox("NULL_IF", True, key="csv_null_if")
                replace_invalid_characters = st.checkbox("REPLACE_INVALID_CHARACTERS", True, key="csv_replace_invalid_characters")
        
        
        
            
            # ------------------------------------------------
            # JSON OPTIONS
            # ------------------------------------------------
            
            if ff_type == "JSON":
            
                st.markdown("### üßæ JSON Settings")
            
                strip_array = st.checkbox("STRIP_OUTER_ARRAY", True, key="json_strip")
                ignore_utf = st.checkbox("IGNORE_UTF8_ERRORS", True, key="json_utf")
            
            # ------------------------------------------------
            # PARQUET OPTIONS
            # ------------------------------------------------
            
            if ff_type == "PARQUET":
            
                st.markdown("### üß± Parquet Settings")
        
                logical = st.checkbox("USE_LOGICAL_TYPE", True, key="pq_logical")
                trim = st.checkbox("TRIM_SPACE", True, key="pq_trim")
                type = st.checkbox("TYPE", True, key="pq_type")
                compression = st.checkbox("COMPRESSION", True, key="pq_compression")
                binary_as_text = st.checkbox("BINARY_AS_TEXT", True, key="pq_binary_as_text")
                use_vectorized_scanner = st.checkbox("USE_VECTORIZED_SCANNER", True, key="pq_use_vectorized_scanner")
                replace_invalid_characters = st.checkbox("REPLACE_INVALID_CHARACTERS", True, key="pq_replace_invalid_characters")
                null_if = st.checkbox("NULL_IF", True, key="pq_null_if")
        
            
            # ------------------------------------------------
            # CREATE FILE FORMAT BUTTON
            # ------------------------------------------------
            
            if st.button("üöÄ Create File Format", key="create_ff_btn", type="primary"):
            
                full_schema = f"{CONFIG_DB}.{CONFIG_SCHEMA}"
            
                try:
            
                    if ff_type == "CSV":
            
                        sql = f"""
            CREATE OR REPLACE FILE FORMAT {full_schema}.{ff_name}
            TYPE = CSV
            PARSE_HEADER = TRUE
            ESCAPE_UNENCLOSED_FIELD = 'NONE'
            TRIM_SPACE = TRUE
            FIELD_OPTIONALLY_ENCLOSED_BY = '"'
            NULL_IF = ('NULL','')
            ERROR_ON_COLUMN_COUNT_MISMATCH = FALSE
            REPLACE_INVALID_CHARACTERS = TRUE
            """
            
                    elif ff_type == "JSON":
            
                        sql = f"""
            CREATE OR REPLACE FILE FORMAT {full_schema}.{ff_name}
            TYPE = JSON
            STRIP_OUTER_ARRAY = {str(strip_array).upper()}
            IGNORE_UTF8_ERRORS = {str(ignore_utf).upper()}
            """
            
                    else:  # PARQUET
            
                        sql = f"""
            CREATE OR REPLACE FILE FORMAT {full_schema}.{ff_name}
                            TYPE = 'PARQUET'
                            COMPRESSION = 'AUTO'
                            -- SNAPPY_COMPRESSION = TRUE
                            BINARY_AS_TEXT = FALSE
                            USE_LOGICAL_TYPE =  {str(logical).upper()}
                            TRIM_SPACE = {str(trim).upper()}
                            USE_VECTORIZED_SCANNER = TRUE
                            REPLACE_INVALID_CHARACTERS = TRUE
                            NULL_IF = ('NULL', 'null', '')"""
            
                    st.code(sql, language="sql")  # preview
                    session.sql(sql).collect()
            
                    st.success(f"‚úÖ File Format `{ff_name}` created")
            
                except Exception as e:
                    st.error(str(e))
        
        with tab3:
            st.markdown("<h2 class='header'>üì• Import Configurations</h2>", unsafe_allow_html=True)
            
            st.markdown("""
            <div class='info-box'>
                <strong>‚ÑπÔ∏è Import Instructions</strong><br>
                Upload an Excel file with CDC configurations. The imported configurations will replace existing ones in the configuration table.
                <br><br>
                <strong>‚ú® Snowpipe Support:</strong> Set the SNOWPIPE column to TRUE to enable automatic data ingestion with Snowpipe.
            </div>
            """, unsafe_allow_html=True)
            
            uploaded_file = st.file_uploader("üìÇ Upload Excel File", type=['xlsx'], help="Upload an Excel file containing CDC configurations")
            
            if uploaded_file:
                try:
                    df = pd.read_excel(uploaded_file)
                    
                    st.markdown("### üìã Preview Imported Data")
                    st.dataframe(df, use_container_width=True)
                    
                    st.info(f"üìä Found {len(df)} configuration(s) in the uploaded file")
                    
                    if st.button("üöÄ File uploaded successfully ‚Äî click Execute to start integration", use_container_width=True):
                        with st.spinner("Importing configurations..."):
                            # Clear existing configs and imported list
                            st.session_state.cdc_configs = {}
                            st.session_state.imported_configs = []
                            
                            # Truncate configuration table before importing
                            try:
                                truncate_config_table(session, f"{st.session_state.config_db}.{st.session_state.config_schema}")
                                st.success("‚úÖ Configuration table cleared")
                            except Exception as e:
                                st.error(f"‚ùå Failed to clear configuration table: {str(e)}")
                            
                            # Import new configurations
                            for _, row in df.iterrows():
                                config_name = row['CONFIG_NAME']
                                staging_schema = f"{st.session_state.config_db}.{row['STAGING_SCHEMA']}"
                                target_schema = f"{st.session_state.config_db}.{row['TARGET_SCHEMA']}"
                                
                                st.session_state.cdc_configs[config_name] = {
                                    "source_url": row['SOURCE_URL'],
                                    "primary_key": row['PRIMARY_KEY'],
                                    "schema": staging_schema,
                                    "gold_schema": target_schema,
                                    "warehouse": row['WAREHOUSE'],
                                    "schedule": row['SCHEDULE'],
                                    "historical_copy": bool(row['HISTORICAL_COPY']),
                                    "snowpipe": bool(row.get('SNOWPIPE', False)),
                                    "task": bool(row['TASK_ENABLED']),
                                    "file_format": row['FILE_FORMAT'],
                                    "description": row['DESCRIPTION'],
                                    "created_at": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                                    "last_modified": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                                }
                                
                                # Track imported configs
                                st.session_state.imported_configs.append(config_name)
                                
                                save_config_to_table(session, f"{st.session_state.config_db}.{st.session_state.config_schema}",
                                                     config_name, st.session_state.cdc_configs[config_name])
                            
                            st.success(f"‚úÖ Imported {len(df)} configuration(s) successfully!")
                            
                            # Show imported configurations
                            st.markdown("### üì¶ Imported Configurations")
                            for config_name in st.session_state.imported_configs:
                                config = st.session_state.cdc_configs[config_name]
                                snowpipe_indicator = " üîÑ [Snowpipe]" if config.get('snowpipe', False) else ""
                                st.markdown(f"<div class='config-badge'>‚úì {config_name}{snowpipe_indicator}</div>", unsafe_allow_html=True)
                            
                            st.rerun()
                except Exception as e:
                    st.error(f"‚ùå Import error: {str(e)}")
            
            st.markdown("---")
            st.markdown("### üì• Download Template")
            st.markdown("Download this template to understand the required format for importing configurations.")
            
            # Template Download
            sample_data = {
                "CONFIG_NAME": ["EXAMPLE_CONFIG"],
                "SOURCE_URL": ["s3://your-bucket/path/"],
                "PRIMARY_KEY": ["ID"],
                "STAGING_SCHEMA": ["SILVER"],
                "TARGET_SCHEMA": ["GOLD"],
                "WAREHOUSE": ["COMPUTE_WH"],
                "SCHEDULE": ["USING CRON 0 * * * * UTC"],
                "HISTORICAL_COPY": [True],
                "SNOWPIPE": [False],
                "STREAM": [False],
                "TASK_ENABLED": [False],
                "FILE_FORMAT": ["CDC_FORMAT"],
                "DESCRIPTION": ["Example configuration"]
            }
            sample_df = pd.DataFrame(sample_data)
            bool_cols = ['HISTORICAL_COPY', 'SNOWPIPE', 'STREAM', 'TASK_ENABLED']
            sample_df[bool_cols] = sample_df[bool_cols].astype(str) 
            
            output = io.BytesIO()
            try:
                with pd.ExcelWriter(output, engine='xlsxwriter', engine_kwargs={'options': {'in_memory': True}}) as writer:
                    sample_df.to_excel(writer, index=False)
            except Exception as e:
                with pd.ExcelWriter(output, engine='openpyxl') as writer:
                    sample_df.to_excel(writer, index=False)
            
            output.seek(0)
            st.download_button(
                "üì• Download Template",
                data=output,
                file_name="Integration_template.xlsx",
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                use_container_width=True
            )
    
        with tab4:
            st.markdown("<h2 class='header'>‚ñ∂Ô∏èExecution</h2>", unsafe_allow_html=True)
        
            if not st.session_state.cdc_configs:
                st.info("‚ÑπÔ∏è No configurations available. Please create a configuration first or import from Excel.")
            else:
                # Show execution mode selection
                st.markdown("### üéØ Execution Mode")
                
                col_mode1, col_mode2 = st.columns(2)
                with col_mode1:
                    st.markdown("""
                    <div class='info-box'>
                        <strong>üì¶ Execute Imported Configurations Only</strong><br>
                        Runs CDC process only for configurations imported from Excel file
                    </div>
                    """, unsafe_allow_html=True)
                with col_mode2:
                    st.markdown("""
                    <div class='info-box'>
                        <strong>üîÑ Execute All Configurations</strong><br>
                        Runs CDC process for all available configurations
                    </div>
                    """, unsafe_allow_html=True)

                file_format = config.get("file_format")

                if "." not in file_format:
                    file_format = f"{st.session_state.config_db}.{st.session_state.config_schema}.{file_format}"

                
                # full_file_format = f"{st.session_state.config_db}.{st.session_state.config_schema}.CDC_FORMAT"
                
                # Display configurations
                st.markdown("### üìã Available Configurations")
                for config_name, config in st.session_state.cdc_configs.items():
                    is_imported = config_name in st.session_state.imported_configs
                    badge = "üÜï IMPORTED" if is_imported else "üìå EXISTING"
                    
                    with st.expander(f"{badge} {config_name}", expanded=False):
                        col1, col2 = st.columns(2)
                        with col1:
                            st.markdown(f"""
                            <div class='object-card'>
                                <div class='object-title'>üóÇÔ∏è Source Details</div>
                                <p><strong>File Format:</strong> {config.get('file_format')}</p>
                                <p><strong>Primary Key:</strong> {config['primary_key']}</p>
                                <p><strong>Source Path:</strong> {config['source_url']}</p>
                            </div>
                            """, unsafe_allow_html=True)
            
                        with col2:
                            st.markdown(f"""
                            <div class='object-card'>
                                <div class='object-title'>‚ùÑÔ∏è Snowflake Details</div>
                                <p><strong>Staging Schema:</strong> {config['schema']}</p>
                                <p><strong>Target Schema:</strong> {config['gold_schema']}</p>
                                <p><strong>Warehouse:</strong> {config['warehouse']}</p>
                            </div>
                            """, unsafe_allow_html=True)
            
                        st.markdown(f"""
                        <div class='object-card'>
                            <div class='object-title'>‚öôÔ∏è Execution Options</div>
                            <p>
                                {'‚úÖ Historical Load' if config['historical_copy'] else '‚ùå Historical Load'}<br>
                                {'‚úÖ Snowpipe Enabled' if config.get('snowpipe', False) else '‚ùå Snowpipe Disabled'}<br>
                                {'‚úÖ Task Enabled' if config['task'] else '‚ùå Task Disabled'}<br>
                                üìÖ Schedule: {config['schedule']}
                            </p>
                        </div>
                        """, unsafe_allow_html=True)
                
                # Execution buttons
                st.markdown("---")
                st.markdown("### üöÄ Execute CDC Process")
                
                col_exec1, col_exec2 = st.columns(2)
                
                with col_exec1:
                    if st.button("üÜï Execute Imported Configurations Only", use_container_width=True, type="primary"):
                        if not st.session_state.imported_configs:
                            st.warning("‚ö†Ô∏è No imported configurations found. Please import configurations first.")
                        else:
                            with st.spinner(f"Executing {len(st.session_state.imported_configs)} imported configuration(s)..."):
                                execution_log = []
                                
                                # Execute only imported configs
                                for config_name in st.session_state.imported_configs:
                                    if config_name in st.session_state.cdc_configs:
                                        config = st.session_state.cdc_configs[config_name]
                                        st.info(f"üîÑ Processing: {config_name}")
                                        run_cdc(session, config_name, config, file_format, execution_log)
                                
                                # Truncate configuration table after execution
                                try:
                                    truncate_config_table(session, f"{st.session_state.config_db}.{st.session_state.config_schema}")
                                    execution_log.append(("Config Table Cleanup", "Success", "Configuration table truncated after execution"))
                                    st.success("‚úÖ Configuration table cleaned up")
                                except Exception as e:
                                    execution_log.append(("Config Table Cleanup", "Failed", str(e)))
                                    st.error(f"‚ùå Failed to truncate configuration table: {str(e)}")
                                
                                # Clear imported configs list after execution
                                st.session_state.imported_configs = []
                                
                                st.markdown("### üìä Execution Summary")
                                success_count = sum(1 for entry in execution_log if entry[1] == "Success")
                                failed_count = sum(1 for entry in execution_log if entry[1] == "Failed")
                                
                                col_sum1, col_sum2, col_sum3 = st.columns(3)
                                with col_sum1:
                                    st.metric("Total Steps", len(execution_log))
                                with col_sum2:
                                    st.metric("‚úÖ Successful", success_count)
                                with col_sum3:
                                    st.metric("‚ùå Failed", failed_count)
                                
                                st.markdown("### üìù Detailed Execution Log")
                                for entry in execution_log:
                                    status_color = "#28a745" if entry[1] == "Success" else ("#ffc107" if entry[1] == "Warning" else "#dc3545")
                                    status_icon = "‚úÖ" if entry[1] == "Success" else ("‚ö†Ô∏è" if entry[1] == "Warning" else "‚ùå")
                                    bg_color = "#e8f8f0" if entry[1] == "Success" else ("#fff3cd" if entry[1] == "Warning" else "#f8e8e8")
                                    st.markdown(f"""
                                    <div style="padding: 15px; margin: 10px 0; border-left: 4px solid {status_color}; background-color: {bg_color}; border-radius: 5px;">
                                        <strong>{status_icon} {entry[0]}</strong> ({entry[1]})<br>
                                        {entry[2]}
                                    </div>
                                    """, unsafe_allow_html=True)
                
                with col_exec2:
                    if st.button("üîÑ Execute All Configurations", use_container_width=True):
                        with st.spinner(f"Executing all {len(st.session_state.cdc_configs)} configuration(s)..."):
                            execution_log = []
                            
                            for config_name, config in st.session_state.cdc_configs.items():
                                st.info(f"üîÑ Processing: {config_name}")
                                run_cdc(session, config_name, config, full_file_format, execution_log)

                            
                            st.markdown("### üìä Execution Summary")
                            success_count = sum(1 for entry in execution_log if entry[1] == "Success")
                            failed_count = sum(1 for entry in execution_log if entry[1] == "Failed")
                            
                            col_sum1, col_sum2, col_sum3 = st.columns(3)
                            with col_sum1:
                                st.metric("Total Steps", len(execution_log))
                            with col_sum2:
                                st.metric("‚úÖ Successful", success_count)
                            with col_sum3:
                                st.metric("‚ùå Failed", failed_count)
                            
                            st.markdown("### üìù Detailed Execution Log")
                            for entry in execution_log:
                                status_color = "#28a745" if entry[1] == "Success" else ("#ffc107" if entry[1] == "Warning" else "#dc3545")
                                status_icon = "‚úÖ" if entry[1] == "Success" else ("‚ö†Ô∏è" if entry[1] == "Warning" else "‚ùå")
                                bg_color = "#e8f8f0" if entry[1] == "Success" else ("#fff3cd" if entry[1] == "Warning" else "#f8e8e8")
                                st.markdown(f"""
                                <div style="padding: 15px; margin: 10px 0; border-left: 4px solid {status_color}; background-color: {bg_color}; border-radius: 5px;">
                                    <strong>{status_icon} {entry[0]}</strong> ({entry[1]})<br>
                                    {entry[2]}
                                </div>
                                """, unsafe_allow_html=True)

        # with tab5:
        #     st.markdown("## üì° Snowpipe Details")
        
        #     pipe_store = st.session_state.get("snowpipe_info", {})
        
        #     if not pipe_store:
        #         st.info("No Snowpipes created yet ‚Äî run CDC with Snowpipe enabled.")
        #     else:
        
        #         cfg = st.selectbox(
        #             "Select Config",
        #             list(pipe_store.keys()),
        #             key="pipe_view_select"
        #         )
        
        #         info = pipe_store[cfg]
        
        #         st.metric("üìå Pipe Name", info.get("pipe", "N/A"))
        #         st.metric("üì° Notification Channel", info.get("notification", "N/A"))
        
        #         if info.get("definition"):
        #             st.markdown("### COPY Definition")
        #             st.code(info["definition"], language="sql")
        
        #         if st.button("üßπ Clear Snowpipe Cache"):
        #             st.session_state.snowpipe_info = {}
        #             st.rerun()
        with tab5:

            st.markdown("## üì° Snowpipe Details")
        
            pipe_store = st.session_state.get("snowpipe_info", {})
        
            if not pipe_store:
                st.info("No Snowpipes available. Run CDC with Snowpipe + STREAM enabled.")
            else:
        
                cfg = st.selectbox(
                    "Select Config",
                    sorted(pipe_store.keys()),
                    key="pipe_view_select"
                )
        
                info = pipe_store.get(cfg, {})
        
                pipe_name = info.get("pipe")
                notification = info.get("notification")
                definition = info.get("definition")
        
                # ---------- PIPE NAME ----------
                if pipe_name:
                    st.success(f"Pipe: {pipe_name}")
                else:
                    st.warning("Pipe name not available")
        
                # ---------- NOTIFICATION ----------
                if notification:
                    st.markdown("**üì° Notification Channel**")
                    st.code(notification)
                else:
                    st.info("Notification channel not found (may not be AUTO_INGEST or DESC PIPE failed)")
        
                # ---------- COPY DEFINITION ----------
                if definition:
                    st.markdown("### COPY Definition")
                    st.code(definition, language="sql")
        
                # ---------- STATUS HINT ----------
                if not pipe_name:
                    st.caption("Snowpipe may have been skipped or failed during creation.")
        
                # ---------- CLEAR CACHE ----------
                if st.button("üßπ Clear Snowpipe Cache", type="secondary"):
                    st.session_state.snowpipe_info = {}
                    st.success("Cache cleared")
                    st.rerun()



    
        with tab6:
            st.markdown("<h2 class='header'>üéØ Single Table Execution</h2>", unsafe_allow_html=True)
            
            st.markdown("""
            <div class='info-box'>
                <strong>‚ÑπÔ∏è Quick Single Table CDC</strong><br>
                Manually configure and execute CDC for a single table without saving to configuration.
                Perfect for testing or one-time operations.
            </div>
            """, unsafe_allow_html=True)
            
            with st.form(key="single_table_form"):
                st.markdown("### üìù Table Configuration")
                
                col1, col2 = st.columns(2)
                
                with col1:
                    single_config_name = st.text_input(
                        "üìå Configuration Name",
                        placeholder="e.g., ORDERS_TABLE",
                        help="Unique identifier for this execution"
                    )
                    
                    single_source_url = st.text_input(
                        "üîó Source S3 URL",
                        placeholder="s3://bucket-name/path/to/files/",
                        help="S3 path containing your source files"
                    )
                    
                    single_primary_key = st.text_input(
                        "üîë Primary Key(s)",
                        placeholder="ORDER_ID or ORDER_ID,LINE_ITEM",
                        help="Comma-separated list of primary key columns"
                    )
                    
                    # Database selection
                    databases = get_databases(session)
                    single_db = st.selectbox(
                        "üíæ Database",
                        databases,
                        index=databases.index(st.session_state.config_db) if st.session_state.config_db in databases else 0
                    )
                    
                    # Staging schema selection
                    staging_schemas = get_schemas(session, single_db)
                    single_staging_schema = st.selectbox(
                        "üìÇ Staging Schema",
                        staging_schemas,
                        help="Schema where staging table and stream will be created"
                    )
                    # # File Format Selection
                    # file_formats = get_file_formats(
                    #     session,
                    #     single_db,
                    #     single_staging_schema
                    # )
                
                    # format_options = file_formats
                
                    # single_file_format = st.selectbox(
                    #     "üìÑ File Format",
                    #     format_options,
                    #     help="Choose existing or auto-create format"
                    # )
                
                with col2:
                    # Target schema selection
                    target_schemas = get_schemas(session, single_db)
                    single_target_schema = st.selectbox(
                        "üéØ Target Schema",
                        target_schemas,
                        help="Schema where final table will be created"
                    )
                    
                    single_warehouse = st.text_input(
                        "üè≠ Warehouse",
                        value="COMPUTE_WH",
                        placeholder="COMPUTE_WH",
                        help="Warehouse to use for task execution"
                    )
                    
                    single_schedule = st.text_input(
                        "‚è∞ Task Schedule",
                        value="USING CRON 0 * * * * UTC",
                        placeholder="USING CRON 0 * * * * UTC",
                        help="Cron schedule for task execution"
                    )
                    # File Format Selection
                    file_formats = get_file_formats(
                        session,
                        single_db,
                        single_staging_schema
                    )
                
                    format_options = file_formats
                
                    single_file_format = st.selectbox(
                        "üìÑ File Format",
                        format_options,
                        help="Choose existing or auto-create format"
                    )
                    
                    # single_file_format = st.text_input(
                    #     "üìÑ File Format",
                    #     value="CDC_FORMAT",
                    #     placeholder="CDC_FORMAT",
                    #     help="File format name to use"
                    # )
                
                st.markdown("### ‚öôÔ∏è Execution Options")
                
                col_opt1, col_opt2, col_opt3 = st.columns(3)
                
                with col_opt1:
                    single_historical = st.checkbox(
                        "üì¶ Historical Load",
                        value=True,
                        help="Load existing data from S3 before starting CDC"
                    )
                
                with col_opt2:
                    single_snowpipe = st.checkbox(
                        "üîÑ Enable Snowpipe",
                        value=False,
                        help="Create Snowpipe for automatic data ingestion"
                    )
                
                with col_opt3:
                    single_task = st.checkbox(
                        "‚ö° Enable Task",
                        value=True,
                        help="Create and start task for CDC processing"
                    )
                
                single_description = st.text_area(
                    "üìù Description (Optional)",
                    placeholder="Enter a description for this CDC configuration...",
                    help="Optional description for documentation purposes"
                )
                
                st.markdown("---")
                
                col_submit1, col_submit2 = st.columns([1, 3])
                
                with col_submit1:
                    submit_single = st.form_submit_button("üöÄ Execute Now", use_container_width=True, type="primary")
                
                with col_submit2:
                    st.markdown("""
                    <div style='padding: 10px; background-color: #fff3cd; border-radius: 5px; margin-top: 5px;'>
                        ‚ö†Ô∏è This will immediately execute CDC setup for the specified table
                    </div>
                    """, unsafe_allow_html=True)
            
            if submit_single:
                # Validation
                if not single_config_name:
                    st.error("‚ùå Configuration name is required!")
                elif not single_source_url:
                    st.error("‚ùå Source S3 URL is required!")
                elif not single_primary_key:
                    st.error("‚ùå Primary key is required!")
                else:
                    with st.spinner(f"üîÑ Executing CDC for {single_config_name}..."):
                        try:
                            # Build configuration dictionary
                            single_config = {
                                "source_url": single_source_url.strip(),
                                "primary_key": single_primary_key.strip(),
                                "schema": f"{single_db}.{single_staging_schema}",
                                "gold_schema": f"{single_db}.{single_target_schema}",
                                "warehouse": single_warehouse.strip(),
                                "schedule": single_schedule.strip(),
                                "historical_copy": single_historical,
                                "snowpipe": single_snowpipe,
                                "task": single_task,
                                "file_format": single_file_format.strip(),
                                "description": single_description.strip()
                            }
                            
                            # Prepare full file format path
                            full_file_format = f"{st.session_state.config_db}.{st.session_state.config_schema}.{single_file_format.strip()}"
                            
                            # Execution log
                            execution_log = []
                            
                            st.info(f"üîÑ Processing: {single_config_name}")
                            
                            # Execute CDC
                            run_cdc(session, single_config_name, single_config, full_file_format, execution_log)
                            
                            # Display results
                            st.markdown("---")
                            st.markdown("### üìä Execution Summary")
                            
                            success_count = sum(1 for entry in execution_log if entry[1] == "Success")
                            failed_count = sum(1 for entry in execution_log if entry[1] == "Failed")
                            warning_count = sum(1 for entry in execution_log if entry[1] == "Warning")
                            
                            col_sum1, col_sum2, col_sum3, col_sum4 = st.columns(4)
                            with col_sum1:
                                st.metric("Total Steps", len(execution_log))
                            with col_sum2:
                                st.metric("‚úÖ Successful", success_count)
                            with col_sum3:
                                st.metric("‚ö†Ô∏è Warnings", warning_count)
                            with col_sum4:
                                st.metric("‚ùå Failed", failed_count)
                            
                            st.markdown("### üìù Detailed Execution Log")
                            for entry in execution_log:
                                status_color = "#28a745" if entry[1] == "Success" else ("#ffc107" if entry[1] == "Warning" else "#dc3545")
                                status_icon = "‚úÖ" if entry[1] == "Success" else ("‚ö†Ô∏è" if entry[1] == "Warning" else "‚ùå")
                                bg_color = "#e8f8f0" if entry[1] == "Success" else ("#fff3cd" if entry[1] == "Warning" else "#f8e8e8")
                                st.markdown(f"""
                                <div style="padding: 15px; margin: 10px 0; border-left: 4px solid {status_color}; background-color: {bg_color}; border-radius: 5px;">
                                    <strong>{status_icon} {entry[0]}</strong> ({entry[1]})<br>
                                    {entry[2]}
                                </div>
                                """, unsafe_allow_html=True)
                            
                            if failed_count == 0:
                                st.success(f"""
                                ‚úÖ **CDC setup completed successfully for {single_config_name}!**
                                
                                **Created Objects:**
                                - Stage: `{single_config['schema']}.{single_source_url.rstrip('/').split('/')[-1]}_STAGE`
                                - Staging Table: `{single_config['schema']}.{single_source_url.rstrip('/').split('/')[-1]}_STAGING`
                                - Target Table: `{single_config['gold_schema']}.{single_source_url.rstrip('/').split('/')[-1]}`
                                - Stream: `{single_config['schema']}.{single_source_url.rstrip('/').split('/')[-1]}_STREAM`
                                {f"- Snowpipe: `{single_config['schema']}.{single_source_url.rstrip('/').split('/')[-1]}_PIPE`" if single_snowpipe else ""}
                                {f"- Task: `{single_config['schema']}.{single_source_url.rstrip('/').split('/')[-1]}_TASK`" if single_task else ""}
                                """)
                            else:
                                st.error(f"‚ùå CDC setup completed with {failed_count} error(s). Please review the execution log above.")
                            
                        except Exception as e:
                            st.error(f"‚ùå Execution failed: {str(e)}")
                            log_action("Single Table Execution", "Failed", str(e), single_config_name)
    
        with tab7:
            st.markdown("<h2 class='header'>üìä CDC Monitoring</h2>", unsafe_allow_html=True)
            
            if not st.session_state.cdc_configs:
                st.info("‚ÑπÔ∏è No configurations available. Please create a configuration first.")
            else:
                selected_config = st.selectbox(
                    "üìã Select Configuration to Monitor",
                    options=list(st.session_state.cdc_configs.keys()),
                    index=0 if not st.session_state.active_config else 
                          list(st.session_state.cdc_configs.keys()).index(st.session_state.active_config)
                )
                config = st.session_state.cdc_configs[selected_config]
                
                base_name = config["source_url"].rstrip('/').split('/')[-1]
                expected_objects = {
                    "stage": f"{base_name}_STAGE",
                    "staging_table": f"{base_name}_STAGING",
                    "target_table": base_name,
                    "stream": f"{base_name}_STREAM",
                    "task": f"{base_name}_TASK",
                    "pipe": f"{base_name}_PIPE"
                }
                
                st.markdown("### üîç CDC Object Status")
                
                # Stage Status
                try:
                    stage = session.sql(f"""
                        SELECT stage_name, stage_type, created
                        FROM {st.session_state.config_db}.INFORMATION_SCHEMA.STAGES
                        WHERE stage_schema = '{config['schema'].split('.')[-1]}'
                        AND stage_name = '{expected_objects['stage']}'
                    """).collect()
                    
                    if stage:
                        st.markdown(f"""
                        <div class='object-card'>
                            <div class='object-title'>üì¶ Stage: {config['schema']}.{expected_objects['stage']}</div>
                            <p><strong>Status:</strong> <span class='status-active'>‚úÖ Active</span></p>
                            <p><strong>Type:</strong> {stage[0]['STAGE_TYPE']}</p>
                            <p><strong>Created:</strong> {stage[0]['CREATED']}</p>
                        </div>
                        """, unsafe_allow_html=True)
                    else:
                        st.markdown(f"""
                        <div class='object-card'>
                            <div class='object-title'>üì¶ Stage: {config['schema']}.{expected_objects['stage']}</div>
                            <p><strong>Status:</strong> <span class='status-inactive'>‚ùå Not Found</span></p>
                        </div>
                        """, unsafe_allow_html=True)
                except Exception as e:
                    st.error(f"‚ùå Error checking stage: {str(e)}")
                
                # Staging Table Status
                try:
                    table = session.sql(f"""
                        SELECT table_name, row_count, created
                        FROM {st.session_state.config_db}.INFORMATION_SCHEMA.TABLES
                        WHERE table_schema = '{config['schema'].split('.')[-1]}'
                        AND table_name = '{expected_objects['staging_table']}'
                    """).collect()
                    
                    if table:
                        st.markdown(f"""
                        <div class='object-card'>
                            <div class='object-title'>üìã Staging Table: {config['schema']}.{expected_objects['staging_table']}</div>
                            <p><strong>Status:</strong> <span class='status-active'>‚úÖ Active</span></p>
                            <p><strong>Rows:</strong> {table[0]['ROW_COUNT']:,}</p>
                            <p><strong>Created:</strong> {table[0]['CREATED']}</p>
                        </div>
                        """, unsafe_allow_html=True)
                    else:
                        st.markdown(f"""
                        <div class='object-card'>
                            <div class='object-title'>üìã Staging Table: {config['schema']}.{expected_objects['staging_table']}</div>
                            <p><strong>Status:</strong> <span class='status-inactive'>‚ùå Not Found</span></p>
                        </div>
                        """, unsafe_allow_html=True)
                except Exception as e:
                    st.error(f"‚ùå Error checking staging table: {str(e)}")
                
                # Target Table Status
                try:
                    table = session.sql(f"""
                        SELECT table_name, row_count, created
                        FROM {st.session_state.config_db}.INFORMATION_SCHEMA.TABLES
                        WHERE table_schema = '{config['gold_schema'].split('.')[-1]}'
                        AND table_name = '{expected_objects['target_table']}'
                    """).collect()
                    
                    if table:
                        st.markdown(f"""
                        <div class='object-card'>
                            <div class='object-title'>üéØ Target Table: {config['gold_schema']}.{expected_objects['target_table']}</div>
                            <p><strong>Status:</strong> <span class='status-active'>‚úÖ Active</span></p>
                            <p><strong>Rows:</strong> {table[0]['ROW_COUNT']:,}</p>
                            <p><strong>Created:</strong> {table[0]['CREATED']}</p>
                        </div>
                        """, unsafe_allow_html=True)
                    else:
                        st.markdown(f"""
                        <div class='object-card'>
                            <div class='object-title'>üéØ Target Table: {config['gold_schema']}.{expected_objects['target_table']}</div>
                            <p><strong>Status:</strong> <span class='status-inactive'>‚ùå Not Found</span></p>
                        </div>
                        """, unsafe_allow_html=True)
                except Exception as e:
                    st.error(f"‚ùå Error checking target table: {str(e)}")
                
                # Stream Status
                try:
                    stream = session.sql(f"""
                        SELECT stream_name, table_name, owner, created
                        FROM {st.session_state.config_db}.INFORMATION_SCHEMA.STREAMS
                        WHERE stream_schema = '{config['schema'].split('.')[-1]}'
                        AND stream_name = '{expected_objects['stream']}'
                    """).collect()
                    
                    if stream:
                        st.markdown(f"""
                        <div class='object-card'>
                            <div class='object-title'>üåä Stream: {config['schema']}.{expected_objects['stream']}</div>
                            <p><strong>Status:</strong> <span class='status-active'>‚úÖ Active</span></p>
                            <p><strong>Source Table:</strong> {stream[0]['TABLE_NAME']}</p>
                            <p><strong>Created:</strong> {stream[0]['CREATED']}</p>
                        </div>
                        """, unsafe_allow_html=True)
                    else:
                        st.markdown(f"""
                        <div class='object-card'>
                            <div class='object-title'>üåä Stream: {config['schema']}.{expected_objects['stream']}</div>
                            <p><strong>Status:</strong> <span class='status-inactive'>‚ùå Not Found</span></p>
                        </div>
                        """, unsafe_allow_html=True)
                except Exception as e:
                    st.error(f"‚ùå Error checking stream: {str(e)}")
                
                # Snowpipe Status
                if config.get("snowpipe", False):
                    try:
                        pipe = session.sql(f"""
                            SELECT pipe_name, pipe_owner, created
                            FROM {st.session_state.config_db}.INFORMATION_SCHEMA.PIPES
                            WHERE pipe_schema = '{config['schema'].split('.')[-1]}'
                            AND pipe_name = '{expected_objects['pipe']}'
                        """).collect()
                        
                        if pipe:
                            st.markdown(f"""
                            <div class='object-card'>
                                <div class='object-title'>üîÑ Snowpipe: {config['schema']}.{expected_objects['pipe']}</div>
                                <p><strong>Status:</strong> <span class='status-active'>‚úÖ Active</span></p>
                                <p><strong>Owner:</strong> {pipe[0]['PIPE_OWNER']}</p>
                                <p><strong>Created:</strong> {pipe[0]['CREATED']}</p>
                            </div>
                            """, unsafe_allow_html=True)
                            
                            # Show pipe status details
                            if st.button("üìä View Snowpipe Execution History", key=f"pipe_history_{selected_config}"):
                                try:
                                    pipe_history = session.sql(f"""
                                        SELECT *
                                        FROM TABLE(INFORMATION_SCHEMA.PIPE_USAGE_HISTORY(
                                            PIPE_NAME => '{config['schema']}.{expected_objects['pipe']}',
                                            DATE_RANGE_START => DATEADD('day', -7, CURRENT_TIMESTAMP())
                                        ))
                                        ORDER BY START_TIME DESC
                                        LIMIT 20
                                    """).to_pandas()
                                    
                                    if not pipe_history.empty:
                                        st.dataframe(pipe_history, use_container_width=True)
                                    else:
                                        st.info("No execution history found for the last 7 days")
                                except Exception as e:
                                    st.warning(f"Could not retrieve pipe history: {str(e)}")
                        else:
                            st.markdown(f"""
                            <div class='object-card'>
                                <div class='object-title'>üîÑ Snowpipe: {config['schema']}.{expected_objects['pipe']}</div>
                                <p><strong>Status:</strong> <span class='status-inactive'>‚ùå Not Found</span></p>
                            </div>
                            """, unsafe_allow_html=True)
                    except Exception as e:
                        st.error(f"‚ùå Error checking Snowpipe: {str(e)}")
                
                # Task Status
                if config["task"]:
                    try:
                        task = session.sql(f"""
                            SELECT task_name, warehouse_name, schedule, state, created
                            FROM {st.session_state.config_db}.INFORMATION_SCHEMA.TASKS
                            WHERE task_schema = '{config['schema'].split('.')[-1]}'
                            AND task_name = '{expected_objects['task']}'
                        """).collect()
                        
                        if task:
                            status_class = "status-active" if task[0]['STATE'] == 'started' else "status-warning"
                            status_icon = "‚úÖ" if task[0]['STATE'] == 'started' else "‚ö†Ô∏è"
                            st.markdown(f"""
                            <div class='object-card'>
                                <div class='object-title'>‚ö° Task: {config['schema']}.{expected_objects['task']}</div>
                                <p><strong>Status:</strong> <span class='{status_class}'>{status_icon} {task[0]['STATE'].capitalize()}</span></p>
                                <p><strong>Warehouse:</strong> {task[0]['WAREHOUSE_NAME']}</p>
                                <p><strong>Schedule:</strong> {task[0]['SCHEDULE']}</p>
                                <p><strong>Created:</strong> {task[0]['CREATED']}</p>
                            </div>
                            """, unsafe_allow_html=True)
                        else:
                            st.markdown(f"""
                            <div class='object-card'>
                                <div class='object-title'>‚ö° Task: {config['schema']}.{expected_objects['task']}</div>
                                <p><strong>Status:</strong> <span class='status-inactive'>‚ùå Not Found</span></p>
                            </div>
                            """, unsafe_allow_html=True)
                    except Exception as e:
                        st.error(f"‚ùå Error checking task: {str(e)}")
                
                # Stream Data Preview
                st.markdown("### üîç Stream Data Preview")
                try:
                    stream_data = session.sql(f"""
                        SELECT COUNT(*) as record_count
                        FROM {config['schema']}.{expected_objects['stream']}
                    """).collect()
                    
                    if stream_data[0]['RECORD_COUNT'] > 0:
                        st.markdown(f"""
                        <div class='info-box'>
                            Stream contains <strong>{stream_data[0]['RECORD_COUNT']:,}</strong> record(s) waiting to be processed.
                        </div>
                        """, unsafe_allow_html=True)
                        
                        if st.button("üëÅÔ∏è Preview Stream Data", use_container_width=True):
                            preview_data = session.sql(f"""
                                SELECT * 
                                FROM {config['schema']}.{expected_objects['stream']}
                                LIMIT 10
                            """).to_pandas()
                            st.dataframe(preview_data, use_container_width=True)
                    else:
                        st.markdown("""
                        <div class='success-box'>
                            ‚úÖ Stream is currently empty (no new changes to process).
                        </div>
                        """, unsafe_allow_html=True)
                except Exception as e:
                    st.error(f"‚ùå Error checking stream data: {str(e)}")
        
        with tab8:
            st.markdown("<h2 class='header'>üìù Execution Logs</h2>", unsafe_allow_html=True)
            
            if not st.session_state.log_entries:
                st.info("‚ÑπÔ∏è No log entries available yet.")
            else:
                col1, col2, col3 = st.columns(3)
                with col1:
                    filter_config = st.selectbox(
                        "üîç Filter by Configuration",
                        options=["All"] + list(st.session_state.cdc_configs.keys())
                    )
                with col2:
                    filter_status = st.selectbox(
                        "üìä Filter by Status",
                        options=["All", "Success", "Failed", "Warning"]
                    )
                with col3:
                    if st.button("üóëÔ∏è Clear All Logs", use_container_width=True):
                        st.session_state.log_entries = []
                        st.rerun()
                
                filtered_logs = st.session_state.log_entries
                if filter_config != "All":
                    filtered_logs = [log for log in filtered_logs if log["config"] == filter_config]
                if filter_status != "All":
                    filtered_logs = [log for log in filtered_logs if log["status"].lower() == filter_status.lower()]
                
                st.markdown(f"### üìã Showing {len(filtered_logs)} log entries")
                
                for log in reversed(filtered_logs):
                    if log["status"] == "Success":
                        st.markdown(f"""
                        <div class='success-box'>
                            <strong>‚úÖ {log['timestamp']} - {log['action']}</strong><br>
                            <em>Configuration:</em> {log['config'] or 'N/A'}<br>
                            {log['message']}
                        </div>
                        """, unsafe_allow_html=True)
                    elif log["status"] == "Failed":
                        st.markdown(f"""
                        <div class='error-box'>
                            <strong>‚ùå {log['timestamp']} - {log['action']}</strong><br>
                            <em>Configuration:</em> {log['config'] or 'N/A'}<br>
                            {log['message']}
                        </div>
                        """, unsafe_allow_html=True)
                    else:
                        st.markdown(f"""
                        <div class='warning-box'>
                            <strong>‚ö†Ô∏è {log['timestamp']} - {log['action']}</strong><br>
                            <em>Configuration:</em> {log['config'] or 'N/A'}<br>
                            {log['message']}
                        </div>
                        """, unsafe_allow_html=True)
                
                # Export logs option
                if filtered_logs:
                    st.markdown("---")
                    st.markdown("### üì• Export Logs")
                    
                    logs_df = pd.DataFrame(filtered_logs)
                    csv = logs_df.to_csv(index=False).encode('utf-8')
                    
                    st.download_button(
                        label="üì• Download Logs as CSV",
                        data=csv,
                        file_name=f"cdc_logs_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                        mime="text/csv",
                        use_container_width=True
                    )

if st.session_state.setup_complete:
    main()
